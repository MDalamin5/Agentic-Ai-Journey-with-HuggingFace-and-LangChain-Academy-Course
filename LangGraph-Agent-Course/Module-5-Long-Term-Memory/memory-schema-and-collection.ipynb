{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38cfcda9",
   "metadata": {},
   "source": [
    "# **Goals**\n",
    "\n",
    "Sometimes we want to save memories to a [collection](https://docs.google.com/presentation/d/181mvjlgsnxudQI6S3ritg9sooNyu4AcLLFH1UK0kIuk/edit#slide=id.g30eb3c8cf10_0_200) rather than single profile. \n",
    "\n",
    "Here we'll update our chatbot to [save memories to a collection](https://langchain-ai.github.io/langgraph/concepts/memory/#collection).\n",
    "\n",
    "We'll also show how to use [Trustcall](https://github.com/hinthornw/trustcall) to update this collection. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31fbfda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from langgraph.store.base import BaseStore\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"langchain-academy\"\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "model = ChatGroq(model_name = \"meta-llama/llama-4-scout-17b-16e-instruct\", groq_api_key=groq_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356cf2d1",
   "metadata": {},
   "source": [
    "## Defining a collection schema\n",
    "\n",
    "Instead of storing user information in a fixed profile structure, we'll create a flexible collection schema to store memories about user interactions.\n",
    "\n",
    "Each memory will be stored as a separate entry with a single `content` field for the main information we want to remember\n",
    "\n",
    "This approach allows us to build an open-ended collection of memories that can grow and change as we learn more about the user.\n",
    "\n",
    "We can define a collection schema as a [Pydantic](https://docs.pydantic.dev/latest/) object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f4368ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Memory(BaseModel):\n",
    "    \"\"\"Tool for storing information about the user for long-term memory.\"\"\"\n",
    "    \n",
    "    content: str = Field(description=\"The main content of the memory. For example: User expressed interest in learning about French.\")\n",
    "\n",
    "class MemoryCollection(BaseModel):\n",
    "    # \"\"\"Tool for storing information about the user for long-term memory.\"\"\"\n",
    "    \n",
    "    memories: list[Memory] = Field(description=\"A list of memories about the user.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3c888611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Memory(content=\"User's name is Al Amin.\"), Memory(content='User likes bike.')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "model_with_structure = model.with_structured_output(MemoryCollection)\n",
    "\n",
    "# Invoke the model to produce structured output that matches the schema\n",
    "memory_collection = model_with_structure.invoke([HumanMessage(\"My name is Al Amin. I like bike.\")])\n",
    "memory_collection.memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8a731391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': \"User's name is Al Amin.\"}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_collection.memories[0].model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "233bc983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'User likes bike.'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_collection.memories[1].model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568f43f2",
   "metadata": {},
   "source": [
    "### Save dictionary representation of each memory to the store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "80dc6a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.store.memory import InMemoryStore\n",
    "import uuid\n",
    "in_memory_store = InMemoryStore()\n",
    "\n",
    "user_id = '1'\n",
    "namespace_for_memory = (user_id, \"memories\")\n",
    "\n",
    "key = str(uuid.uuid4())\n",
    "value = memory_collection.memories[0].model_dump()\n",
    "in_memory_store.put(namespace_for_memory, key, value)\n",
    "\n",
    "key = str(uuid.uuid4())\n",
    "value = memory_collection.memories[1].model_dump()\n",
    "in_memory_store.put(namespace_for_memory, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fc44f944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'namespace': ['1', 'memories'], 'key': 'aa765124-817e-43b4-b1a8-125d5d28a13f', 'value': {'content': \"User's name is Al Amin.\"}, 'created_at': '2025-05-13T05:57:07.259249+00:00', 'updated_at': '2025-05-13T05:57:07.259249+00:00', 'score': None}\n",
      "{'namespace': ['1', 'memories'], 'key': '4233b6cf-9517-476d-babb-cb117c78faac', 'value': {'content': 'User likes bike.'}, 'created_at': '2025-05-13T05:57:07.259249+00:00', 'updated_at': '2025-05-13T05:57:07.259249+00:00', 'score': None}\n"
     ]
    }
   ],
   "source": [
    "# Search \n",
    "for m in in_memory_store.search(namespace_for_memory):\n",
    "    print(m.dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce0d344",
   "metadata": {},
   "source": [
    "## ***Updating collection schema***\n",
    "\n",
    "We discussed the challenges with updating a profile schema in the last lesson. \n",
    "\n",
    "The same applies for collections! \n",
    "\n",
    "We want the ability to update the collection with new memories as well as update existing memories in the collection. \n",
    "\n",
    "Now we'll show that [Trustcall](https://github.com/hinthornw/trustcall) can be also used to update a collection. \n",
    "\n",
    "This enables both addition of new memories as well as [updating existing memories in the collection](https://github.com/hinthornw/trustcall?tab=readme-ov-file#simultanous-updates--insertions\n",
    ").\n",
    "\n",
    "Let's define a new extractor with Trustcall. \n",
    "\n",
    "As before, we provide the schema for each memory, `Memory`.  \n",
    "\n",
    "But, we can supply `enable_inserts=True` to allow the extractor to insert new memories to the collection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "45d76161",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trustcall import create_extractor\n",
    "\n",
    "# Create the extractor\n",
    "trustcall_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[Memory],\n",
    "    tool_choice=\"Memory\",\n",
    "    enable_inserts=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7f3fffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "# Instruction\n",
    "instruction = \"\"\"Extract memories from the following conversation:\"\"\"\n",
    "\n",
    "# Conversation\n",
    "conversation = [HumanMessage(content=\"Hi, I'm Al Amin.\"), \n",
    "                AIMessage(content=\"Nice to meet you, Al Amin.\"), \n",
    "                HumanMessage(content=\"This morning I had a nice bike ride in Bashundhara r/a, Dhaka.\")]\n",
    "\n",
    "# Invoke the extractor\n",
    "result = trustcall_extractor.invoke({\"messages\": [SystemMessage(content=instruction)] + conversation})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f495f952",
   "metadata": {},
   "source": [
    "#### above error by model.But code is correct. hare need `gpt-4o` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c6dd5a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_6tzp)\n",
      " Call ID: call_6tzp\n",
      "  Args:\n",
      "    content: Al Amin had a bike ride in Bashundhara r/a, Dhaka.\n"
     ]
    }
   ],
   "source": [
    "# Messages contain the tool calls\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5be549b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Al Amin had a bike ride in Bashundhara r/a, Dhaka.'\n"
     ]
    }
   ],
   "source": [
    "# Responses contain the memories that adhere to the schema\n",
    "for m in result[\"responses\"]: \n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "905115ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'call_6tzp'}\n"
     ]
    }
   ],
   "source": [
    "# Metadata contains the tool call  \n",
    "for m in result[\"response_metadata\"]: \n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a07dd08c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0',\n",
       "  'Memory',\n",
       "  {'content': 'Al Amin had a bike ride in Bashundhara r/a, Dhaka.'})]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update the conversation\n",
    "updated_conversation = [AIMessage(content=\"That's great, did you do after?\"), \n",
    "                        HumanMessage(content=\"I went to Tartine and ate a croissant.\"),                        \n",
    "                        AIMessage(content=\"What else is on your mind?\"),\n",
    "                        HumanMessage(content=\"I was thinking about my Japan, and going back this winter!\"),]\n",
    "\n",
    "# Update the instruction\n",
    "system_msg = \"\"\"Update existing memories and create new ones based on the following conversation:\"\"\"\n",
    "\n",
    "# We'll save existing memories, giving them an ID, key (tool name), and value\n",
    "tool_name = \"Memory\"\n",
    "existing_memories = [(str(i), tool_name, memory.model_dump()) for i, memory in enumerate(result[\"responses\"])] if result[\"responses\"] else None\n",
    "existing_memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "46161037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the extractor with our updated conversation and existing memories\n",
    "result = trustcall_extractor.invoke({\"messages\": updated_conversation, \n",
    "                                     \"existing\": existing_memories})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3db5ec66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_bqkh)\n",
      " Call ID: call_bqkh\n",
      "  Args:\n",
      "    content: Al Amin had a bike ride in Bashundhara r/a, Dhaka. He went to Tartine and ate a croissant. He was thinking about Japan and going back this winter.\n"
     ]
    }
   ],
   "source": [
    "# Messages from the model indicate two tool calls were made\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e27cbdd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Al Amin had a bike ride in Bashundhara r/a, Dhaka. He went to Tartine and ate a croissant. He was thinking about Japan and going back this winter.'\n"
     ]
    }
   ],
   "source": [
    "# Responses contain the memories that adhere to the schema\n",
    "for m in result[\"responses\"]: \n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6ac31c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'call_bqkh'}\n"
     ]
    }
   ],
   "source": [
    "# Metadata contains the tool call  \n",
    "for m in result[\"response_metadata\"]: \n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d94b52",
   "metadata": {},
   "source": [
    "## Chatbot with collection schema updating\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "Now, let's bring Trustcall into our chatbot to create and update a memory collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "85a6196f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "import uuid\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langchain_core.messages import merge_message_runs\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.store.base import BaseStore\n",
    "from langchain_groq import ChatGroq\n",
    "# from langgraph.prebuilt import create_extractor\n",
    "\n",
    "# Initialize the model\n",
    "model = ChatGroq(model_name = \"meta-llama/llama-4-scout-17b-16e-instruct\", groq_api_key=groq_api_key)\n",
    "\n",
    "# Memory schema with proper description\n",
    "class Memory(BaseModel):\n",
    "    \"\"\"Tool for storing information about the user for long-term memory.\"\"\"\n",
    "    \n",
    "    content: str = Field(\n",
    "        description=\"The main content of the memory. For example: User expressed interest in learning about French.\"\n",
    "    )\n",
    "\n",
    "# Create the Trustcall extractor\n",
    "trustcall_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[Memory],\n",
    "    tool_choice=\"Memory\",\n",
    "    # This allows the extractor to insert new memories\n",
    "    enable_inserts=True,\n",
    ")\n",
    "\n",
    "# Chatbot instruction\n",
    "MODEL_SYSTEM_MESSAGE = \"\"\"You are a helpful chatbot. You are designed to be a companion to a user. \n",
    "\n",
    "You have a long term memory which keeps track of information you learn about the user over time.\n",
    "\n",
    "Current Memory (may include updated memories from this conversation): \n",
    "\n",
    "{memory}\"\"\"\n",
    "\n",
    "# Trustcall instruction\n",
    "TRUSTCALL_INSTRUCTION = \"\"\"Reflect on following interaction. \n",
    "\n",
    "Use the provided tools to retain any necessary memories about the user. \n",
    "\n",
    "Use parallel tool calling to handle updates and insertions simultaneously:\"\"\"\n",
    "\n",
    "def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"Load memories from the store and use them to personalize the chatbot's response.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Retrieve memory from the store\n",
    "    namespace = (\"memories\", user_id)\n",
    "    memories = store.search(namespace)\n",
    "\n",
    "    # Format the memories for the system prompt\n",
    "    info = \"\\n\".join(f\"- {mem.value['content']}\" for mem in memories)\n",
    "    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=info)\n",
    "\n",
    "    # Respond using memory as well as the chat history\n",
    "    response = model.invoke([SystemMessage(content=system_msg)]+state[\"messages\"])\n",
    "\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"Reflect on the chat history and update the memory collection.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Define the namespace for the memories\n",
    "    namespace = (\"memories\", user_id)\n",
    "\n",
    "    # Retrieve the most recent memories for context\n",
    "    existing_items = store.search(namespace)\n",
    "\n",
    "    # Format the existing memories for the Trustcall extractor\n",
    "    tool_name = \"Memory\"\n",
    "    existing_memories = ([(existing_item.key, tool_name, existing_item.value)\n",
    "                          for existing_item in existing_items]\n",
    "                          if existing_items\n",
    "                          else None\n",
    "                        )\n",
    "\n",
    "    # Merge the chat history and the instruction\n",
    "    updated_messages=list(merge_message_runs(messages=[SystemMessage(content=TRUSTCALL_INSTRUCTION)] + state[\"messages\"]))\n",
    "\n",
    "    # Invoke the extractor\n",
    "    result = trustcall_extractor.invoke({\"messages\": updated_messages, \n",
    "                                        \"existing\": existing_memories})\n",
    "\n",
    "    # Save the memories from Trustcall to the store\n",
    "    for r, rmeta in zip(result[\"responses\"], result[\"response_metadata\"]):\n",
    "        store.put(namespace,\n",
    "                  rmeta.get(\"json_doc_id\", str(uuid.uuid4())),\n",
    "                  r.model_dump(mode=\"json\"),\n",
    "            )\n",
    "\n",
    "# Define the graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"call_model\", call_model)\n",
    "builder.add_node(\"write_memory\", write_memory)\n",
    "builder.add_edge(START, \"call_model\")\n",
    "builder.add_edge(\"call_model\", \"write_memory\")\n",
    "builder.add_edge(\"write_memory\", END)\n",
    "\n",
    "# Store for long-term (across-thread) memory\n",
    "across_thread_memory = InMemoryStore()\n",
    "\n",
    "# Checkpointer for short-term (within-thread) memory\n",
    "within_thread_memory = MemorySaver()\n",
    "\n",
    "# Compile the graph with the checkpointer fir and store\n",
    "graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9d8c8ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Assalamualikum, i'm Al Amin\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Wa alaikumussalam, Al Amin! It's nice to meet you. I'm here to chat and help with any questions or topics you'd like to discuss. How are you doing today? \n",
      "\n",
      "(By the way, I'll make sure to remember your name, Al Amin, for our future conversations!)\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory \n",
    "config = {\"configurable\": {\"thread_id\": \"3\", \"user_id\": \"3\"}}\n",
    "\n",
    "# User input \n",
    "input_messages = [HumanMessage(content=\"Assalamualikum, i'm Al Amin\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "19391ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I like to bike Bashundhara r/a, Dhaka\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Bashundhara Residential Area in Dhaka is a lovely place to bike around. The roads are relatively smooth, and it's a great way to explore the area. Are you a regular biker, Al Amin? Do you have a favorite route or spot in Bashundhara R/A that you like to visit on your bike?\n"
     ]
    }
   ],
   "source": [
    "# User input \n",
    "input_messages = [HumanMessage(content=\"I like to bike Bashundhara r/a, Dhaka\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6530f30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'namespace': ['memories', '3'], 'key': 'd05fee14-1d56-4c38-b82d-de345c40096a', 'value': {'content': 'User introduced himself as Al Amin.'}, 'created_at': '2025-05-13T06:02:37.108009+00:00', 'updated_at': '2025-05-13T06:02:37.108009+00:00', 'score': None}\n",
      "{'namespace': ['memories', '3'], 'key': 'fec93391-d275-40af-83f2-50a94ece93bf', 'value': {'content': 'Al Amin likes biking in Bashundhara r/a, Dhaka.'}, 'created_at': '2025-05-13T06:02:54.687744+00:00', 'updated_at': '2025-05-13T06:02:54.687744+00:00', 'score': None}\n"
     ]
    }
   ],
   "source": [
    "# Namespace for the memory to save\n",
    "user_id = \"3\"\n",
    "namespace = (\"memories\", user_id)\n",
    "memories = across_thread_memory.search(namespace)\n",
    "for m in memories:\n",
    "    print(m.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f28f041b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I also enjoy going to bakeries\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "A sweet tooth, Al Amin? Bakeries can be a wonderful treat. Are you particularly fond of any specific types of baked goods, like pastries, cakes, or bread? Or are there any bakeries in Dhaka that you especially enjoy visiting? \n",
      "\n",
      "(By the way, I recall you mentioned biking in Bashundhara R/A earlier. Maybe you've stopped by a bakery or two after a ride?)\n"
     ]
    }
   ],
   "source": [
    "# User input \n",
    "input_messages = [HumanMessage(content=\"I also enjoy going to bakeries\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaef8e1",
   "metadata": {},
   "source": [
    "## Chat with a new Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3c7a17a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What bakeries do you recommend for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Al Amin, that's you! I recall that you mentioned enjoying bakeries in Bashundhara r/a, Dhaka. Unfortunately, I don't have specific bakery recommendations stored in my memory. However, I can suggest that you try searching online for highly-rated bakeries in Bashundhara r/a, Dhaka. You can also ask locals or check social media for recommendations.\n",
      "\n",
      "That being said, I can try to help you brainstorm or provide general information about bakeries. Would you like me to do that?\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory \n",
    "config = {\"configurable\": {\"thread_id\": \"4\", \"user_id\": \"3\"}}\n",
    "\n",
    "# User input \n",
    "input_messages = [HumanMessage(content=\"What bakeries do you recommend for me?\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d3269531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What Restaurant do you recommend for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "As Al Amin, I recall that you enjoy biking in Bashundhara r/a, Dhaka. If you're looking for a restaurant recommendation, I'd be happy to help. However, I don't have specific restaurant recommendations stored in my memory.\n",
      "\n",
      "That being said, since you mentioned you enjoy bakeries, I can suggest looking for restaurants that have a bakery or caf√© attached to them. Alternatively, you can try searching online for highly-rated restaurants in Bashundhara r/a, Dhaka.\n",
      "\n",
      "If you'd like, I can also try to provide general information about restaurants in the area or help you brainstorm options. Would you like me to do that?\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory \n",
    "config = {\"configurable\": {\"thread_id\": \"4\", \"user_id\": \"3\"}}\n",
    "\n",
    "# User input \n",
    "input_messages = [HumanMessage(content=\"What Restaurant do you recommend for me?\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f43ba589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can you tell some name its helps a lot?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "As Al Amin, I recall that you were looking for bakery and restaurant recommendations in Bashundhara r/a, Dhaka. While I don't have a comprehensive list, I can suggest a few options that might be worth trying:\n",
      "\n",
      "For bakeries:\n",
      "\n",
      "* Impress Bakery (I've heard it's a popular spot)\n",
      "* Bashundhara Bakery (conveniently located in the area)\n",
      "* Apollo Bakery (known for their delicious treats)\n",
      "\n",
      "For restaurants:\n",
      "\n",
      "* The Bashundhara (a restaurant with a variety of cuisines)\n",
      "* The Coffee Bean & Tea Leaf (a great spot for coffee and snacks)\n",
      "* Some popular food courts or cafes in the Bashundhara r/a area\n",
      "\n",
      "Keep in mind that these are just suggestions, and you may want to check reviews or ask locals for more recommendations. I hope this helps, and I'm happy to try to provide more information if you need it!\n"
     ]
    }
   ],
   "source": [
    "input_messages = [HumanMessage(content=\"Can you tell some name its helps a lot?\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f0844f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'namespace': ['memories', '3'], 'key': 'd05fee14-1d56-4c38-b82d-de345c40096a', 'value': {'content': 'User introduced himself as Al Amin.'}, 'created_at': '2025-05-13T06:02:37.108009+00:00', 'updated_at': '2025-05-13T06:02:37.108009+00:00', 'score': None}\n",
      "{'namespace': ['memories', '3'], 'key': 'fec93391-d275-40af-83f2-50a94ece93bf', 'value': {'content': 'Al Amin likes biking in Bashundhara r/a, Dhaka.'}, 'created_at': '2025-05-13T06:02:54.687744+00:00', 'updated_at': '2025-05-13T06:02:54.687744+00:00', 'score': None}\n",
      "{'namespace': ['memories', '3'], 'key': '61868eee-0264-4d48-869b-eaa29119caf1', 'value': {'content': 'Al Amin enjoys biking in Bashundhara r/a, Dhaka and likes bakeries.'}, 'created_at': '2025-05-13T06:03:23.141822+00:00', 'updated_at': '2025-05-13T06:03:23.141822+00:00', 'score': None}\n",
      "{'namespace': ['memories', '3'], 'key': '793e0070-df1f-4aea-b4da-3647771a21ae', 'value': {'content': 'User asked for bakery recommendations.'}, 'created_at': '2025-05-13T06:03:47.819591+00:00', 'updated_at': '2025-05-13T06:03:47.819591+00:00', 'score': None}\n",
      "{'namespace': ['memories', '3'], 'key': '2a9576b4-6d7c-4e67-b7f2-06a5bcd5e79c', 'value': {'content': 'User asked for bakery recommendations in Bashundhara r/a, Dhaka.'}, 'created_at': '2025-05-13T06:04:24.880835+00:00', 'updated_at': '2025-05-13T06:04:24.880835+00:00', 'score': None}\n",
      "{'namespace': ['memories', '3'], 'key': '3c470756-c0a0-4f17-987d-894521b15749', 'value': {'content': 'User asked for restaurant recommendations.'}, 'created_at': '2025-05-13T06:05:59.080140+00:00', 'updated_at': '2025-05-13T06:05:59.080140+00:00', 'score': None}\n",
      "{'namespace': ['memories', '3'], 'key': 'c50d0fbc-091f-482d-b964-75b73d87c932', 'value': {'content': 'User asked for bakery and restaurant recommendations in Bashundhara r/a, Dhaka. Impress Bakery, Bashundhara Bakery, and Apollo Bakery are popular spots for bakeries. The Bashundhara, The Coffee Bean & Tea Leaf, and some popular food courts or cafes in the Bashundhara r/a area are recommended for restaurants.'}, 'created_at': '2025-05-13T06:07:06.024906+00:00', 'updated_at': '2025-05-13T06:07:06.024906+00:00', 'score': None}\n"
     ]
    }
   ],
   "source": [
    "# Namespace for the memory to save\n",
    "user_id = \"3\"\n",
    "namespace = (\"memories\", user_id)\n",
    "memories = across_thread_memory.search(namespace)\n",
    "for m in memories:\n",
    "    print(m.dict())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_aca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
