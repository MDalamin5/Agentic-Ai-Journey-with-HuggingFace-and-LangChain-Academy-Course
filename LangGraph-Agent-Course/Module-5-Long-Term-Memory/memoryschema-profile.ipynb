{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac5a3b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from langgraph.store.base import BaseStore\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"langchain-academy\"\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "model = ChatGroq(model_name = \"meta-llama/llama-4-scout-17b-16e-instruct\", groq_api_key=groq_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d44ed6",
   "metadata": {},
   "source": [
    "## ***Defining a user profile Schema***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7887d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "\n",
    "class UserProfile(TypedDict):\n",
    "    user_name: str # the user preferred name\n",
    "    interests: List[str] ## a list of user interest\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81f16c7",
   "metadata": {},
   "source": [
    "#### Saving schema to the store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8270072",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_profile: UserProfile = {\n",
    "    'user_name': \"Al Amin\",\n",
    "    'interests': [\"Biking\", \"reading\", 'Programming']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8b52f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use put method to save this data into the memory\n",
    "\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "in_memory_store = InMemoryStore()\n",
    "\n",
    "user_id = \"1\"\n",
    "namespace_for_memory = (user_id, 'memory')\n",
    "\n",
    "key = \"user_profile\"\n",
    "value = user_profile\n",
    "\n",
    "in_memory_store.put(namespace_for_memory, key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4beb96d3",
   "metadata": {},
   "source": [
    "## search the storing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47ae282e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'namespace': ['1', 'memory'], 'key': 'user_profile', 'value': {'user_name': 'Al Amin', 'interests': ['Biking', 'reading', 'Programming']}, 'created_at': '2025-05-12T09:38:40.365853+00:00', 'updated_at': '2025-05-12T09:38:40.365853+00:00', 'score': None}\n"
     ]
    }
   ],
   "source": [
    "for m in in_memory_store.search(namespace_for_memory):\n",
    "    print(m.dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291965fa",
   "metadata": {},
   "source": [
    "## we can also use get to retrieve a specific object by namespace abd key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca535cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_name': 'Al Amin', 'interests': ['Biking', 'reading', 'Programming']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile = in_memory_store.get(namespace_for_memory, \"user_profile\")\n",
    "profile.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c249ba0a",
   "metadata": {},
   "source": [
    "# ***Chatbot with profile Schema***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd3acca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_name': 'Al Amin', 'interests': ['biking', 'reading', 'Programming']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "\n",
    "\n",
    "# Bind schema to model\n",
    "model_with_structure = model.with_structured_output(UserProfile)\n",
    "\n",
    "# Invoke the model to produce structured output that matches the schema\n",
    "structured_output = model_with_structure.invoke([HumanMessage(\"My name is Al Amin, I like to bike, reading, and Programming.\")])\n",
    "structured_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d739b0",
   "metadata": {},
   "source": [
    "#### Now, lets use this with out chatbot\n",
    "- the only requires minor changes to the `write_memory` function\n",
    "- we use `model_with_structured`, as defined above, to produce a profile that matches our schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7e7b5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.store.base import BaseStore\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "\n",
    "# Chatbot instruction\n",
    "MODEL_SYSTEM_MESSAGE = \"\"\"You are a helpful assistant with memory that provides information about the user. \n",
    "If you have memory for this user, use it to personalize your responses.\n",
    "Here is the memory (it may be empty): {memory}\"\"\"\n",
    "\n",
    "# Create new memory from the chat history and any existing memory\n",
    "CREATE_MEMORY_INSTRUCTION = \"\"\"Create or update a user profile memory based on the user's chat history. \n",
    "This will be saved for long-term memory. If there is an existing memory, simply update it. \n",
    "Here is the existing memory (it may be empty): {memory}\"\"\"\n",
    "\n",
    "def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Load memory from the store and use it to personalize the chatbot's response.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Retrieve memory from the store\n",
    "    namespace = (\"memory\", user_id)\n",
    "    existing_memory = store.get(namespace, \"user_memory\")\n",
    "\n",
    "    # Format the memories for the system prompt\n",
    "    if existing_memory and existing_memory.value:\n",
    "        memory_dict = existing_memory.value\n",
    "        formatted_memory = (\n",
    "            f\"Name: {memory_dict.get('user_name', 'Unknown')}\\n\"\n",
    "            f\"Interests: {', '.join(memory_dict.get('interests', []))}\"\n",
    "        )\n",
    "    else:\n",
    "        formatted_memory = None\n",
    "\n",
    "    # Format the memory in the system prompt\n",
    "    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=formatted_memory)\n",
    "\n",
    "    # Respond using memory as well as the chat history\n",
    "    response = model.invoke([SystemMessage(content=system_msg)]+state[\"messages\"])\n",
    "\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Reflect on the chat history and save a memory to the store.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Retrieve existing memory from the store\n",
    "    namespace = (\"memory\", user_id)\n",
    "    existing_memory = store.get(namespace, \"user_memory\")\n",
    "\n",
    "    # Format the memories for the system prompt\n",
    "    if existing_memory and existing_memory.value:\n",
    "        memory_dict = existing_memory.value\n",
    "        formatted_memory = (\n",
    "            f\"Name: {memory_dict.get('user_name', 'Unknown')}\\n\"\n",
    "            f\"Interests: {', '.join(memory_dict.get('interests', []))}\"\n",
    "        )\n",
    "    else:\n",
    "        formatted_memory = None\n",
    "        \n",
    "    # Format the existing memory in the instruction\n",
    "    system_msg = CREATE_MEMORY_INSTRUCTION.format(memory=formatted_memory)\n",
    "\n",
    "    # Invoke the model to produce structured output that matches the schema\n",
    "    new_memory = model_with_structure.invoke([SystemMessage(content=system_msg)]+state['messages'])\n",
    "\n",
    "    # Overwrite the existing use profile memory\n",
    "    key = \"user_memory\"\n",
    "    store.put(namespace, key, new_memory)\n",
    "\n",
    "# Define the graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"call_model\", call_model)\n",
    "builder.add_node(\"write_memory\", write_memory)\n",
    "builder.add_edge(START, \"call_model\")\n",
    "builder.add_edge(\"call_model\", \"write_memory\")\n",
    "builder.add_edge(\"write_memory\", END)\n",
    "\n",
    "# Store for long-term (across-thread) memory\n",
    "across_thread_memory = InMemoryStore()\n",
    "\n",
    "# Checkpointer for short-term (within-thread) memory\n",
    "within_thread_memory = MemorySaver()\n",
    "\n",
    "# Compile the graph with the checkpointer fir and store\n",
    "graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "714adcd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Asslamualikum, my name is Al Amin and I like to bike around Bashundhara r/a, Dhaka and eat at bakeries.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Wa Alaikumussalam Al Amin! Nice to meet you! It sounds like you enjoy exploring Bashundhara Residential Area (R/A) in Dhaka on your bike. That's a great way to stay active and appreciate the local scenery.\n",
      "\n",
      "Bakeries are a wonderful treat! What's your favorite type of baked good? Do you have a go-to bakery in Bashundhara R/A or do you like to try different ones?\n",
      "\n",
      "(By the way, I'll make sure to remember your name and interests for our future conversations!)\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory \n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n",
    "\n",
    "# User input \n",
    "input_messages = [HumanMessage(content=\"Asslamualikum, my name is Al Amin and I like to bike around Bashundhara r/a, Dhaka and eat at bakeries.\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9adfaa",
   "metadata": {},
   "source": [
    "## Lets check the memory in the store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8264b985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item(namespace=['memory', '1'], key='user_memory', value={'user_name': 'Al Amin', 'interests': ['biking', 'bakeries', 'Bashundhara R/A, Dhaka']}, created_at='2025-05-12T09:55:34.156603+00:00', updated_at='2025-05-12T09:55:34.156603+00:00')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Namespace for hte memory to save\n",
    "user_id = \"1\"\n",
    "namespace = (\"memory\", user_id)\n",
    "key = \"user_memory\"\n",
    "\n",
    "existing_memory = across_thread_memory.get(namespace, key)\n",
    "existing_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0611241c",
   "metadata": {},
   "source": [
    "## When can this fail?\n",
    "\n",
    "[`with_structured_output`](https://python.langchain.com/docs/concepts/structured_outputs/#recommended-usage) is very useful, but what happens if we're working with a more complex schema? \n",
    "\n",
    "[Here's](https://github.com/hinthornw/trustcall?tab=readme-ov-file#complex-schema) an example of a more complex schema, which we'll test below. \n",
    "\n",
    "This is a [Pydantic](https://docs.pydantic.dev/latest/) model that describes a user's preferences for communication and trust fall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37e609fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "class OutputFormat(BaseModel):\n",
    "    preference: str\n",
    "    sentence_preference_revealed: str\n",
    "\n",
    "class TelegramPreferences(BaseModel):\n",
    "    preferred_encoding: Optional[List[OutputFormat]] = None\n",
    "    favorite_telegram_operators: Optional[List[OutputFormat]] = None\n",
    "    preferred_telegram_paper: Optional[List[OutputFormat]] = None\n",
    "\n",
    "class MorseCode(BaseModel):\n",
    "    preferred_key_type: Optional[List[OutputFormat]] = None\n",
    "    favorite_morse_abbreviations: Optional[List[OutputFormat]] = None\n",
    "\n",
    "class Semaphore(BaseModel):\n",
    "    preferred_flag_color: Optional[List[OutputFormat]] = None\n",
    "    semaphore_skill_level: Optional[List[OutputFormat]] = None\n",
    "\n",
    "class TrustFallPreferences(BaseModel):\n",
    "    preferred_fall_height: Optional[List[OutputFormat]] = None\n",
    "    trust_level: Optional[List[OutputFormat]] = None\n",
    "    preferred_catching_technique: Optional[List[OutputFormat]] = None\n",
    "\n",
    "class CommunicationPreferences(BaseModel):\n",
    "    telegram: TelegramPreferences\n",
    "    morse_code: MorseCode\n",
    "    semaphore: Semaphore\n",
    "\n",
    "class UserPreferences(BaseModel):\n",
    "    communication_preferences: CommunicationPreferences\n",
    "    trust_fall_preferences: TrustFallPreferences\n",
    "\n",
    "class TelegramAndTrustFallPreferences(BaseModel):\n",
    "    pertinent_user_preferences: UserPreferences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f85c323",
   "metadata": {},
   "source": [
    "Now, let's try extraction of this schema using the `with_structured_output` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e91406f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '>{\\n  \"pertinent_user_preferences\": {\\n    \"communication_preferences\": {\\n      \"telegram\": {\\n        \"preferred_encoding\": [\\n          {\"preference\": \"Morse code\", \"sentence_preference_revealed\": \"Morse, please. I love using a straight key.\"},\\n          {\"preference\": \"standard encoding\", \"sentence_preference_revealed\": \"\"}\\n        ],\\n        \"preferred_telegram_paper\": [\\n          {\"preference\": \"Daredevil\", \"sentence_preference_revealed\": \"Perfect! Send it by your fastest carrier pigeon.\"}\\n        ],\\n        \"favorite_telegram_operators\": []\\n      },\\n      \"morse_code\": {\\n        \"preferred_key_type\": [\\n          {\"preference\": \"straight key\", \"sentence_preference_revealed\": \"Morse, please. I love using a straight key.\"}\\n        ],\\n        \"favorite_morse_abbreviations\": []\\n      },\\n      \"semaphore\": {\\n        \"preferred_flag_color\": [],\\n        \"semaphore_skill_level\": []\\n      }\\n    },\\n    \"trust_fall_preferences\": {\\n      \"preferred_fall_height\": [\\n        {\"preference\": \"higher fall\", \"sentence_preference_revealed\": \"Tell him I\\'m ready for a higher fall, and I prefer the diamond formation for catching.\"}\\n      ],\\n      \"preferred_catching_technique\": [\\n        {\"preference\": \"diamond formation\", \"sentence_preference_revealed\": \"Tell him I\\'m ready for a higher fall, and I prefer the diamond formation for catching.\"}\\n      ],\\n      \"trust_level\": []\\n    }\\n  }\\n}</function=TelegramAndTrustFallPreferences>'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Invoke the model\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     \u001b[43mmodel_with_structure\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\"\"\u001b[39;49m\u001b[33;43mExtract the preferences from the following conversation:\u001b[39;49m\n\u001b[32m     20\u001b[39m \u001b[33;43m    <convo>\u001b[39;49m\n\u001b[32m     21\u001b[39m \u001b[33;43m    \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mconversation\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\n\u001b[32m     22\u001b[39m \u001b[33;43m    </convo>\u001b[39;49m\u001b[33;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     24\u001b[39m     \u001b[38;5;28mprint\u001b[39m(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\anaconda3\\envs\\lang_aca\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3032\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3030\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   3031\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3032\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3033\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3034\u001b[39m         \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\anaconda3\\envs\\lang_aca\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5416\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5409\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5410\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5411\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5414\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5415\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5416\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5417\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5418\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5419\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5420\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\anaconda3\\envs\\lang_aca\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:370\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    358\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    359\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    360\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    365\u001b[39m     **kwargs: Any,\n\u001b[32m    366\u001b[39m ) -> BaseMessage:\n\u001b[32m    367\u001b[39m     config = ensure_config(config)\n\u001b[32m    368\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    369\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    380\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\anaconda3\\envs\\lang_aca\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:947\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    938\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    939\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    940\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    944\u001b[39m     **kwargs: Any,\n\u001b[32m    945\u001b[39m ) -> LLMResult:\n\u001b[32m    946\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m947\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\anaconda3\\envs\\lang_aca\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:766\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    763\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    764\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    765\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m766\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    767\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    768\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    769\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    770\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    771\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    772\u001b[39m         )\n\u001b[32m    773\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    774\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\anaconda3\\envs\\lang_aca\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1012\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1010\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1011\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1016\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\anaconda3\\envs\\lang_aca\\Lib\\site-packages\\langchain_groq\\chat_models.py:498\u001b[39m, in \u001b[36mChatGroq._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    493\u001b[39m message_dicts, params = \u001b[38;5;28mself\u001b[39m._create_message_dicts(messages, stop)\n\u001b[32m    494\u001b[39m params = {\n\u001b[32m    495\u001b[39m     **params,\n\u001b[32m    496\u001b[39m     **kwargs,\n\u001b[32m    497\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m498\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\anaconda3\\envs\\lang_aca\\Lib\\site-packages\\groq\\resources\\chat\\completions.py:355\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, exclude_domains, frequency_penalty, function_call, functions, include_domains, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_format, response_format, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    177\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    221\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    222\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    223\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    224\u001b[39m \u001b[33;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[32m    225\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    353\u001b[39m \u001b[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m    354\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/openai/v1/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\anaconda3\\envs\\lang_aca\\Lib\\site-packages\\groq\\_base_client.py:1222\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1208\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1209\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1210\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1217\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1218\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1219\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1220\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1221\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1222\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\anaconda3\\envs\\lang_aca\\Lib\\site-packages\\groq\\_base_client.py:1031\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1028\u001b[39m             err.response.read()\n\u001b[32m   1030\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1031\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1033\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1035\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '>{\\n  \"pertinent_user_preferences\": {\\n    \"communication_preferences\": {\\n      \"telegram\": {\\n        \"preferred_encoding\": [\\n          {\"preference\": \"Morse code\", \"sentence_preference_revealed\": \"Morse, please. I love using a straight key.\"},\\n          {\"preference\": \"standard encoding\", \"sentence_preference_revealed\": \"\"}\\n        ],\\n        \"preferred_telegram_paper\": [\\n          {\"preference\": \"Daredevil\", \"sentence_preference_revealed\": \"Perfect! Send it by your fastest carrier pigeon.\"}\\n        ],\\n        \"favorite_telegram_operators\": []\\n      },\\n      \"morse_code\": {\\n        \"preferred_key_type\": [\\n          {\"preference\": \"straight key\", \"sentence_preference_revealed\": \"Morse, please. I love using a straight key.\"}\\n        ],\\n        \"favorite_morse_abbreviations\": []\\n      },\\n      \"semaphore\": {\\n        \"preferred_flag_color\": [],\\n        \"semaphore_skill_level\": []\\n      }\\n    },\\n    \"trust_fall_preferences\": {\\n      \"preferred_fall_height\": [\\n        {\"preference\": \"higher fall\", \"sentence_preference_revealed\": \"Tell him I\\'m ready for a higher fall, and I prefer the diamond formation for catching.\"}\\n      ],\\n      \"preferred_catching_technique\": [\\n        {\"preference\": \"diamond formation\", \"sentence_preference_revealed\": \"Tell him I\\'m ready for a higher fall, and I prefer the diamond formation for catching.\"}\\n      ],\\n      \"trust_level\": []\\n    }\\n  }\\n}</function=TelegramAndTrustFallPreferences>'}}"
     ]
    }
   ],
   "source": [
    "from pydantic import ValidationError\n",
    "\n",
    "# Bind schema to model\n",
    "model_with_structure = model.with_structured_output(TelegramAndTrustFallPreferences)\n",
    "\n",
    "# Conversation\n",
    "conversation = \"\"\"Operator: How may I assist with your telegram, sir?\n",
    "Customer: I need to send a message about our trust fall exercise.\n",
    "Operator: Certainly. Morse code or standard encoding?\n",
    "Customer: Morse, please. I love using a straight key.\n",
    "Operator: Excellent. What's your message?\n",
    "Customer: Tell him I'm ready for a higher fall, and I prefer the diamond formation for catching.\n",
    "Operator: Done. Shall I use our \"Daredevil\" paper for this daring message?\n",
    "Customer: Perfect! Send it by your fastest carrier pigeon.\n",
    "Operator: It'll be there within the hour, sir.\"\"\"\n",
    "\n",
    "# Invoke the model\n",
    "try:\n",
    "    model_with_structure.invoke(f\"\"\"Extract the preferences from the following conversation:\n",
    "    <convo>\n",
    "    {conversation}\n",
    "    </convo>\"\"\")\n",
    "except ValidationError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7109727a",
   "metadata": {},
   "source": [
    "If we naively extract more complex schemas, even using high capacity model like `gpt-4o`, it is prone to failure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0bf222",
   "metadata": {},
   "source": [
    "# ***Trustcall for creating and updating profile schemas***\n",
    "\n",
    "As we can see, working with schemas can be tricky.\n",
    "\n",
    "Complex schemas can be difficult to extract. \n",
    "\n",
    "In addition, updating even simple schemas can pose challenges.\n",
    "\n",
    "Consider our above chatbot. \n",
    "\n",
    "We regenerated the profile schema *from scratch* each time we chose to save a new memory.\n",
    "\n",
    "This is inefficient, potentially wasting model tokens if the schema contains a lot of information to re-generate each time.\n",
    "\n",
    "Worse, we may loose information when regenerating the profile from scratch.\n",
    "\n",
    "Addressing these problems is the motivation for [TrustCall](https://github.com/hinthornw/trustcall)!\n",
    "\n",
    "This is an open-source library for updating JSON schemas developed by one [Will Fu-Hinthorn](https://github.com/hinthornw) on the LangChain team.\n",
    "\n",
    "It's motivated by exactly these challenges while working on memory.\n",
    "\n",
    "Let's first show simple usage of extraction with TrustCall on this list of [messages](https://python.langchain.com/docs/concepts/messages/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80d5a115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversation\n",
    "conversation = [HumanMessage(content=\"Hi, I'm ALmain.\"), \n",
    "                AIMessage(content=\"Nice to meet you, Alamin.\"), \n",
    "                HumanMessage(content=\"I really like biking around Bashundhara r/a dhaka.\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32b9c61",
   "metadata": {},
   "source": [
    "We use `create_extractor`, passing in the model as well as our schema as a [tool](https://python.langchain.com/docs/concepts/tools/).\n",
    "\n",
    "With TrustCall, can supply supply the schema in various ways. \n",
    "\n",
    "For example, we can pass a JSON object / Python dictionary or Pydantic model.\n",
    "\n",
    "Under the hood, TrustCall uses [tool calling](https://python.langchain.com/docs/concepts/tool_calling/) to produce [structured output](https://python.langchain.com/docs/concepts/structured_outputs/) from an input list of [messages](https://python.langchain.com/docs/concepts/messages/).\n",
    "\n",
    "To force Trustcall to produce [structured output](https://python.langchain.com/docs/concepts/structured_outputs/), we can include the schema name in the `tool_choice` argument.\n",
    "\n",
    "We can invoke the extractor with  the above conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0270e3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trustcall import create_extractor\n",
    "\n",
    "# Schema \n",
    "class UserProfile(BaseModel):\n",
    "    \"\"\"User profile schema with typed fields\"\"\"\n",
    "    user_name: str = Field(description=\"The user's preferred name\")\n",
    "    interests: List[str] = Field(description=\"A list of the user's interests\")\n",
    "\n",
    "# Initialize the model\n",
    "model = ChatGroq(model_name = \"meta-llama/llama-4-scout-17b-16e-instruct\", groq_api_key=groq_api_key)\n",
    "\n",
    "# Create the extractor\n",
    "trustcall_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[UserProfile],\n",
    "    tool_choice=\"UserProfile\"\n",
    ")\n",
    "\n",
    "# Instruction\n",
    "system_msg = \"Extract the user profile from the following conversation\"\n",
    "\n",
    "# Invoke the extractor\n",
    "result = trustcall_extractor.invoke({\"messages\": [SystemMessage(content=system_msg)]+conversation})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ff263e",
   "metadata": {},
   "source": [
    "When we invoke the extractor, we get a few things:\n",
    "\n",
    "* `messages`: The list of `AIMessages` that contain the tool calls. \n",
    "* `responses`: The resulting parsed tool calls that match our schema.\n",
    "* `response_metadata`: Applicable if updating existing tool calls. It says which of the responses correspond to which of the existing objects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ac31b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UserProfile (call_w7y7)\n",
      " Call ID: call_w7y7\n",
      "  Args:\n",
      "    user_name: ALmain\n",
      "    interests: ['biking', 'Bashundhara r/a dhaka']\n"
     ]
    }
   ],
   "source": [
    "for m in result['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a41b8d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[UserProfile(user_name='ALmain', interests=['biking', 'Bashundhara r/a dhaka'])]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = result['responses']\n",
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "140bdc72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_name': 'ALmain', 'interests': ['biking', 'Bashundhara r/a dhaka']}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema[0].model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df79d382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'call_w7y7'}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['response_metadata']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e700d390",
   "metadata": {},
   "source": [
    "Let's see how we can use it to *update* the profile.\n",
    "\n",
    "For updating, TrustCall takes a set of messages as well as the existing schema. \n",
    "\n",
    "The central idea is that it prompts the model to produce a [JSON Patch](https://jsonpatch.com/) to update only the relevant parts of the schema.\n",
    "\n",
    "This is less error-prone than naively overwriting the entire schema.\n",
    "\n",
    "It's also more efficient since the model only needs to generate the parts of the schema that have changed.\n",
    "\n",
    "We can save the existing schema as a dict.\n",
    "\n",
    "We can use `model_dump()` to serialize a Pydantic model instance into a dict. \n",
    "\n",
    "We pass it to the `\"existing\"` argument along with the schema name, `UserProfile`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aee9d709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the conversation\n",
    "updated_conversation = [HumanMessage(content=\"Hi, I'm Al amin.\"), \n",
    "                        AIMessage(content=\"Nice to meet you, Alamin.\"), \n",
    "                        HumanMessage(content=\"I really like biking around Bashundhara r/a Dhaka.\"),\n",
    "                        AIMessage(content=\"It sounds like you enjoy exploring Bashundhara Residential Area (R/A) in Dhaka on your bike. That's a great way to stay active and appreciate the local scenery.Bakeries are a wonderful treat! What's your favorite type of baked good? Do you have a go-to bakery in Bashundhara R/A or do you like to try different ones?Where do you go after biking?\"),\n",
    "                        HumanMessage(content=\"I really like to go to a bakery after biking.\"),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3d364bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the instruction\n",
    "system_msg = f\"\"\"Update the memory (JSON doc) to incorporate new information from the following conversation\"\"\"\n",
    "\n",
    "# Invoke the extractor with the updated instruction and existing profile with the corresponding tool name (UserProfile)\n",
    "result  = trustcall_extractor.invoke({\"messages\": [SystemMessage(content=system_msg)]+updated_conversation},\n",
    "                                     {\"existing\": {\"UpdateProfile\": schema[0].model_dump()}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3704fdb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_name': 'Al amin', 'interests': ['biking', 'bakery']}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_schema = result[\"responses\"][0]\n",
    "updated_schema.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e16d488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UserProfile (call_q79v)\n",
      " Call ID: call_q79v\n",
      "  Args:\n",
      "    user_name: Al amin\n",
      "    interests: ['biking', 'bakery']\n"
     ]
    }
   ],
   "source": [
    "for m in result['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5d3238ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'call_q79v'}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['response_metadata']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e07e32",
   "metadata": {},
   "source": [
    "## Now play with a challenging schema the previously has error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "53a5a767",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"'tools.0.function.description' : Value is not nullable\", 'type': 'invalid_request_error'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Conversation\u001b[39;00m\n\u001b[32m      8\u001b[39m conversation = \u001b[33m\"\"\"\u001b[39m\u001b[33mOperator: How may I assist with your telegram, sir?\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[33mCustomer: I need to send a message about our trust fall exercise.\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[33mOperator: Certainly. Morse code or standard encoding?\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m \u001b[33mCustomer: Perfect! Send it by your fastest carrier pigeon.\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[33mOperator: It\u001b[39m\u001b[33m'\u001b[39m\u001b[33mll be there within the hour, sir.\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m result = \u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\"\"\u001b[39;49m\u001b[33;43mExtract the preferences from the following conversation:\u001b[39;49m\n\u001b[32m     20\u001b[39m \u001b[33;43m<convo>\u001b[39;49m\n\u001b[32m     21\u001b[39m \u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mconversation\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\n\u001b[32m     22\u001b[39m \u001b[33;43m</convo>\u001b[39;49m\u001b[33;43m\"\"\"\u001b[39;49m\n\u001b[32m     23\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Extract the preferences\u001b[39;00m\n\u001b[32m     26\u001b[39m result[\u001b[33m\"\u001b[39m\u001b[33mresponses\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\anaconda3\\envs\\lang_aca\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3034\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3032\u001b[39m                 \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m   3033\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3034\u001b[39m                 \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config)\n\u001b[32m   3035\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3036\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\anaconda3\\envs\\lang_aca\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2823\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[39m\n\u001b[32m   2820\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]] = []\n\u001b[32m   2821\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2823\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2824\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2825\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2826\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2827\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2828\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2829\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2830\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2831\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2832\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2833\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2834\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2835\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2836\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2837\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mints\u001b[49m\u001b[43m \u001b[49m\u001b[43m:=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINTERRUPT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m   2838\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\anaconda3\\envs\\lang_aca\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2461\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2455\u001b[39m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   2456\u001b[39m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[32m   2457\u001b[39m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   2458\u001b[39m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   2459\u001b[39m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[32m   2460\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m loop.tick(input_keys=\u001b[38;5;28mself\u001b[39m.input_channels):\n\u001b[32m-> \u001b[39m\u001b[32m2461\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2462\u001b[39m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2463\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2464\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2465\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2466\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2467\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2468\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2469\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\anaconda3\\envs\\lang_aca\\Lib\\site-packages\\langgraph\\pregel\\runner.py:153\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[39m\n\u001b[32m    151\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m                \u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\anaconda3\\envs\\lang_aca\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     38\u001b[39m     task.writes.clear()\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     42\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\anaconda3\\envs\\lang_aca\\Lib\\site-packages\\langgraph\\utils\\runnable.py:623\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    621\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    622\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m623\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    625\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\anaconda3\\envs\\lang_aca\\Lib\\site-packages\\langgraph\\utils\\runnable.py:377\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    375\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\anaconda3\\envs\\lang_aca\\Lib\\site-packages\\trustcall\\_base.py:646\u001b[39m, in \u001b[36m_Extract.invoke\u001b[39m\u001b[34m(self, state, config)\u001b[39m\n\u001b[32m    645\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\u001b[38;5;28mself\u001b[39m, state: ExtractionState, config: RunnableConfig) -> \u001b[38;5;28mdict\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m646\u001b[39m     msg = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound_llm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    647\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tear_down(msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\anaconda3\\envs\\lang_aca\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5416\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5409\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5410\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5411\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5414\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5415\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5416\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5417\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5418\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5419\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5420\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\anaconda3\\envs\\lang_aca\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:370\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    358\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    359\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    360\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    365\u001b[39m     **kwargs: Any,\n\u001b[32m    366\u001b[39m ) -> BaseMessage:\n\u001b[32m    367\u001b[39m     config = ensure_config(config)\n\u001b[32m    368\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    369\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    380\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\anaconda3\\envs\\lang_aca\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:947\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    938\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    939\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    940\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    944\u001b[39m     **kwargs: Any,\n\u001b[32m    945\u001b[39m ) -> LLMResult:\n\u001b[32m    946\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m947\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\anaconda3\\envs\\lang_aca\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:766\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    763\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    764\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    765\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m766\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    767\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    768\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    769\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    770\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    771\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    772\u001b[39m         )\n\u001b[32m    773\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    774\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\anaconda3\\envs\\lang_aca\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1012\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1010\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1011\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1016\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\anaconda3\\envs\\lang_aca\\Lib\\site-packages\\langchain_groq\\chat_models.py:498\u001b[39m, in \u001b[36mChatGroq._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    493\u001b[39m message_dicts, params = \u001b[38;5;28mself\u001b[39m._create_message_dicts(messages, stop)\n\u001b[32m    494\u001b[39m params = {\n\u001b[32m    495\u001b[39m     **params,\n\u001b[32m    496\u001b[39m     **kwargs,\n\u001b[32m    497\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m498\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\anaconda3\\envs\\lang_aca\\Lib\\site-packages\\groq\\resources\\chat\\completions.py:355\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, exclude_domains, frequency_penalty, function_call, functions, include_domains, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_format, response_format, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    177\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    221\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    222\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    223\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    224\u001b[39m \u001b[33;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[32m    225\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    353\u001b[39m \u001b[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m    354\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/openai/v1/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\anaconda3\\envs\\lang_aca\\Lib\\site-packages\\groq\\_base_client.py:1222\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1208\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1209\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1210\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1217\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1218\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1219\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1220\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1221\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1222\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\anaconda3\\envs\\lang_aca\\Lib\\site-packages\\groq\\_base_client.py:1031\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1028\u001b[39m             err.response.read()\n\u001b[32m   1030\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1031\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1033\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1035\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': \"'tools.0.function.description' : Value is not nullable\", 'type': 'invalid_request_error'}}",
      "During task with name 'extract' and id '3873ebed-b37d-8cb1-8618-df2e6cd3754c'"
     ]
    }
   ],
   "source": [
    "bound = create_extractor(\n",
    "    model,\n",
    "    tools=[TelegramAndTrustFallPreferences],\n",
    "    tool_choice=\"TelegramAndTrustFallPreferences\",\n",
    ")\n",
    "\n",
    "# Conversation\n",
    "conversation = \"\"\"Operator: How may I assist with your telegram, sir?\n",
    "Customer: I need to send a message about our trust fall exercise.\n",
    "Operator: Certainly. Morse code or standard encoding?\n",
    "Customer: Morse, please. I love using a straight key.\n",
    "Operator: Excellent. What's your message?\n",
    "Customer: Tell him I'm ready for a higher fall, and I prefer the diamond formation for catching.\n",
    "Operator: Done. Shall I use our \"Daredevil\" paper for this daring message?\n",
    "Customer: Perfect! Send it by your fastest carrier pigeon.\n",
    "Operator: It'll be there within the hour, sir.\"\"\"\n",
    "\n",
    "result = bound.invoke(\n",
    "    f\"\"\"Extract the preferences from the following conversation:\n",
    "<convo>\n",
    "{conversation}\n",
    "</convo>\"\"\"\n",
    ")\n",
    "\n",
    "# Extract the preferences\n",
    "result[\"responses\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f14ebe5",
   "metadata": {},
   "source": [
    "### *Still this model can not solve this problem because this problem solve will be gpt-4o model. see you next time*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0085e660",
   "metadata": {},
   "source": [
    "# **Chatbot with profile schema updating**\n",
    "\n",
    "Now, let's bring Trustcall into our chatbot to create *and update* a memory profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a47bc3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJIAAAFNCAIAAABkBqGXAAAQAElEQVR4nOydCVwTV/7AX04CCQkk3DdyeCAgCOJd74OiUkXrXbe2rlprbdet2stWbGv/q6t2e2irq61db0StWJdWrVfVioKCN6KI3EcScp/8fzqWsjVgxUzCC+/74ZPPZGYyzMx33nu/997MG3ZDQwMi4AYbETCEaMMSog1LiDYsIdqwhGjDEntqqyzWKuUmrdqkVZlMBjzqIWwuw8mFxXNhCdzY3kFOyE4wbF9vK76ivpWvvHVRyRexhRKOM5/F4zM5XCbCAYPerFHBdWaW1+g1ClNYrKBDtCC4swuyLTbVVlOqO7qrWqc2dUxwjYhzdfPkIJyRVhpu5imu5yhcXFkDxntJfLnIVthO27Hd1UUFyh7DJVG9hMixuHy6/uwPtXAh9nvOA9kEW2iDLOXAhjKfEF6vZAmLw0COiNHQcDqrtqpE++yLfpDnI5qhXZu0Un9wU3nPZI+wGD5ydG6cV5z7se7ZmX505//0aoMQcffae8On+3gG2C3osjFVJbrsLRXj5gc4C1iINmhMziZjw/71ZX3HeLQfZ4BXoFOf0R4Hvi4zmxB90JjazhyshbC++xB31P44l10H57XHcDGiB7pSm0JqvHtd3T6dAYlDxUX5KpWcrhRHl7ZT+2qSRkhQu4WBkkaIT+6vRvRAizalzFgvNdi+7aBNEdqVD/VxdT0tCY4WbTdzldG9RajdE91HBM0oiAZo0qYIibJ1LW3AgAEVFRXoCdm+ffsHH3yA6CEgwrkwT4lowPraIIfUacy01loepbS0VKlszQm6evUqog2RB0clN9KRT1q/46byro6+RlWorvznP/85ePBgcXFxWFhYz549Z8+eff78+Tlz5sDSlJSUwYMHf/LJJ4WFhRkZGb/++iukP1ht7NixqampsMKNGzcmT568du3aHTt21NfXczic3NxcmP/9999DsgsPD0fWxt2bCy1eVs97rK8N+s+gRwrRw9atW9etW7d48eI+ffocOXLkiy++EAqFU6dOXb169euvv37gwAEfHx9YbdWqVZWVlUuWLGEwGEVFRcuXLw8KCoqPj+dy719PGzZsGDp0aFxcXOfOnadPnw5ely5diuiBx2dp1WZkbWjQpjLxXOiqV0DiSEhIgFQF0+PGjUtMTNTr9Y+utmLFCpVK5efnB9OwfmZm5qlTp0AbtbR3796Q5pBNAG06DQ6ZJIvFoK+ZMzo6GlJYeno6pJWBAwdCGrK4mtls3rZt28mTJ0tKSqg5kZGRjUshkSEbQsfZsH6ygD5DtYKu1oFp06YtWrSopqbm/fffh2IMPuvq6v6wDjh79dVXL1y48Nprrx07diwnJ6dr167UIsgz4ZPH4yFboa438l2tnzasv0UXV7ZaYUT0wGQyxz7g1q1bEHGsX79eq9VClth0HQgOr127Bou6d+9OzZHL5dQE1QBryw59uIJdhNYv6a2vzdmVVVumR/QAQUdUVFRoaGjYA2pra3/66Sf0WzKioCRJJA+b1kAhZJUxMTEWN9j0h1YHro/qezoXGlKb9TNJ6CE0Gsywu4gGsrKy/v73v584cQLC9+PHj8NEt27dYH5AQAB8ZmdnX7lypUOHDiAD6glQk7t9+/aaNWsgKmmuJu7v75+fnw8ZqUwmQ9amqkQPV4XIEwdtLDYjLEZw95oa0QBE6sHBwRDrDxo06KOPPoLPN998E+aHhISMGDHiiwdAHQAi/ry8PGg3WbhwIZRzkKlC3Q7KxUc3CIugLHzllVegnoCszd1rqrBYAZNp/QRNS3/bnSvqE5nVU5cEMZiOeefIn8Fsbvg2vXjwRK/AjtZvUqelghXUyRkyh+vnaWmOw4Vrvyo4ToyASGdEA7TclQzZQt9UT0hwkfECJstCgisvL580aVIzv2VCrmVxUVpa2rx58xA9LFiwAPJVi4ugRk81rzzK5s2bIX9+dH6DGf3637qhU71pCnlovCkh8/NS7yBe71EWOktBDLRiWPwVBPTN1augCZG+KpdarTaZTE+6S3w+H66zR+ef3FdTV6Ef/Vc/RA80aoOugO0rSwZO8GoPt9o1Bbobj2VUTVwYJHCj6xELGu/cgp1Oecn3yPZKmioDbRM42J93VY3+qz99zhCt2gCfEN7A570gt7xzWYXaAbcvq+BgBz3v5RVI7z2GtriZvPy2NmtjeffB7nED3ZDjkvOjNO+YdPQsfy/6H6Cy0aMbCqlh37oyaGV+ZpynxNfR7natKdX9vLsaOhrHzPZzdbfFY0Q2fVCq4JT8wlGpX5gzNKP4hzlzeXg809Yceq35XqGm6JKyrEgTP8i9qw3verLDY4lQABTmKu9cVQnFHLE3182L4+7FtfG9J61GrTTJqvTSKgPE90qZIaQzPyLONbiLQz+W+Acq7mhrK/TyaoOsRq9VWbnnHjoHUJN+AGvhzGe6eXJFHhyxDxcCLmQn7KmNVqC/DVooZs2ahRwRMlIClhBtWEK0YQnRhiVEG5YQbVhCtGEJ0YYlRBuWEG1YQrRhCdGGJUQblhBtWEK0YQnRhiVEG5YQbVhCtGEJ0YYlRBuWEG1YQrRhCdGGJUQblhBtWEK0YQnRhiVEG5YQbVhCtGEJ0YYlRBuWEG1YQrRhCdGGJUQblhBtWEK0YQnRhiWONpxMSkpKwwOo0WFdXV3NZjODwcjKykIOhKOlNn9//3PnzjUOhEvJS0xMRI4F3mPMPcq0adPc3P5n1EqRSDR9+nTkWDiatr59+3bs2LHpnPDw8F69eiHHwtG0AZMnT4YURk07ZFJDDqmtX79+jW9ri4iI6NOnD3I4HFAb+i3BOWpSQ1aMJOsq9BolXW/be1I6+CZEdegHE8FecaWFGtQ2cBawxD7Wednu09bbtCrzmYO1twtUsE9srmOmXWth1Js1SmNotKBnsuQpX9/6VNoghe35rDSqt1vXPu6I8Oe4dFx69axs3KsB7t6tH8O89c7NpoZD31TEDhATZ09ETH/32GfEh74phxOIWkvrtUGZAQm1U6LtRlF3GDr1EDWYUfkdLWotrddWU6b3DqHl5WTtATh1T/MG19ZHkgqpUSi2TlzUDnF159TXGlBreZoKgGOORG8zzObWn0DS34YlRBuWEG1YQrRhCdGGJUQblhBtWEK0YQnRhiVEG5YQbVjSpvuji4oKBw5OKCi4CNPvLf37m4vmIZszZVrqF1+ubnmdjIxtw0bY9J4+ktqwhGjDEptqM5lMO3Zu+XbL1wwGI6pLzIt/mdOlSzTM/+WX40d/zr546YJSqegaFTt1ysyYmDj05ECmOvPliZ9/tvmLL/95+fIlXx+/KVNe7NI5+t2lCysqyuB/LZi/uEOHcGrlTZvXHT58qKq60sfHLz4u8bX5i2CvYP6dO0UrPll6t+ROXFzi9Gkvs1i/vxC8rq728y9WFVy+qNPpkpL6wFJ/vwBkD2xatq1bv/bgwb3py1a9vWS5u1iyaMmrpWX3tFrtRyveNRqNSxYv+3D5ai8vn7ffeb1eUY+eHA7n/k01n32+cuaLc48ezunYscv6rz799F//9967Hx86eKqhoeHLdQ9LKXB2ICtz7pw3MnZnw9nP/jFr3/7dMN9gMMBe+fr6b/kmc+Zf5m7dukkmraN+AtfcgjdmgbOFf3t308adfBf+3FdeqKysQPbAdtrkctnujK0TJ76QmNCzb98BC994p1tsQl1tDY/H+/qrbQteWxzXLQH+Zs2ar1Qpr1zJR08OlVyGDB4J24GJ/v0HKxT1E8ZPjYzoxGaze/fqf7Pw+v09qZdv2/7NC9Nn9e7d31XgOmTwiNQxE7759iuz2Xz8xJGqqso5s1+XSDwgXYJXhVJBbfxSfm5JSfFbi9Nh/93dxfNeWejs7LwnczuyB7bLJCHzgU9IAdRXJyen9GUrqWmNWr1x4+d5F8/X1tZQc+rqatCTQ908GBwcSn11ceHDZ2jow1yRzxeoVEqYKCstgVTVqVNU4w/DwiJlMmllVUVpaQlcRl5e3tR8b28fN7eH96VBQAuLYmPjqa9MJjM6Oi4vLwfZA9tpUyjv53tOXKc/zId8Zv6CmYkJvd5752MofiAvGpHcyrv2KW1Ummuk8Sv1uCJM1D64JnhOvMZ1XJxd0IOrR14vA7tNf+7Me3ibE5S7kJ9DhaTpUkiUyB7YTpuA7wqfao36D/MhGAFVi958H65l+Cr9rSyhD0qMVvf7/W7UXoEDoauISpGNqNQqagKW8vl8KJibLmWz7BOK2+6/hod3hALm0qULnR7kk6Bq8ZL5w4ePguIHziPlDPj52I+IZiBLhPgwPz8PyjxqzpWr+WBFJHKD7BGSVHHxbSqnvXq1oL5eTq0Dma1KpfL29vXz9afmQDwlEdsntdkuJBEIBBAs7Nu369B/v8/Ny1n76ScQ8UdFxcDpgCIN4joIJk+fPgFnCop6iAsQbQhdhUOGjNzy3Qb4dxBx/HBof1ZWZtq4ybCoT58BcG39c81HIK+6uurjT5aCS+pXEInA38qV6bBvUBBm7Nk+e87UH386iOyBTdM41I3gjKxctRySGlzpEO5D1crH2/f27cJ/b/py1T8/hMrQmwvfEwpFENdpNOrhw1IQPcybuxA1oGXLl8C14u8fCFHl+LQp6IHRjz5cs2HDZymjn4EMAELKAwf2ND4mseLjTzP37vwgfTEEukFBIckjU0eljEX2oPWPbhzfU80TcDsnkZvJW8PVMzKtytB/rCdqFaRxC0sw07Z12+Zt2zZbXNQhLGLt6q9R+wAzbaNGjRs4cJjFRRx26x8Xww7MtEFbFPyhdg8p27CEaMMSog1LiDYsIdqwhGjDEqINS4g2LCHasKT12pgsRoOZDJbQSsxmxGIzUGtpfTep2Icrq279gCjtHHm1XuLrhFpL67V5+juVFqqNBpLgnhiDrqHslsrD3y7aApz8w5zPHapGhCckJ7s6INLFw6/1Yyg97XiSP++urqs0dHtG7ObF5TiR8SRbwqAzSyv1F4/VSny5z4xrZb82hRVe33D3uvry6fryIo1a0VZGb22buAhZfiHOUX1EgZFPO8Sco711o5H169czGIxZs2YhR4TU27CEaMMSog1LiDYsIdqwhGjDEqINS4g2LCHasIRowxKiDUuINiwh2rCEaMMSog1LiDYsIdqwhGjDEqINS4g2LCHasIRowxKiDUuINiwh2rCEaMMSog1LiDYsIdqwhGjDEqINS4g2LCHasIRowxKiDUuINiwh2rCEaMMSog1LiDYsIdqwxNFGAZo4cWJhYWHTOXCAHTp02LVrF3IgHG1ws7S0NCen/xnwj8fjTZkyBTkWDqgtMDCw6Rz4mpqaihwLBxxKcPz48Y1vOuVyuRMmTEAOhwNqe+655/z9H771NTg4eOxY+7yHklYcUBuTyYQUBiWcoyY15MDjSVLCdu7ciRyRx2i7d1NTcEpeflujqicjs9oCvojlG+oc01fkF9bSCK8taTuxt6ayWBc3SOLmxeXyyDjItkCvNcuqYGfIIAAADktJREFU9LmHa3xCeX3HNPsu9ma15f4sK7+t6zfWGxHswYmMSr8wp27PuFlcajkNQZaYe1SWlPxUo2cTnoakZz1BgUZpuWyyrK2sSOMVxCMZox2Bk+8ZwCu/rbW41LIYaYVe5NH6lwsQrIKbJ7e6VGdxkWVtJmMDi9X6F+cQrAKDyTCbLEcepOMGS4g2LCHasIRowxKiDUuINiwh2rCEaMMSog1LiDYsIdqwhGjDErt1zRQW3hg4OKGg4CIiPDl20+buLp4+7SVPz/u950VFhVOmjkGEP43dMkmJxOMvM2ZT09euX0aEJ8E6qW1s2rAt322kpmtrayD3W/7RO41LR6cO2rNne0bGtgkTk8/lnJnx4vj1X33amElu2rzuHyvTy8pL4euezB2wfl1dbfryt56f9Gzq2CEff7K0tOzeY3cgY8/28c+PvHHzWtqEEUOH93xp1qTrN64eO344ZfQzySn9lqUvUSgV1JrNbfzPbwGAfZ46LXXYiF7TZ4xbs3YFdT8OdURnzp5atGT+3Hkz5i94adHiV5vu5OK3Xtu56ztkDayjrXv3pCtX86np8+fPisWSK5cvUV9v376lUNQnJPTkcLkqlXLXru+mT3s5JeX3O4UhzU0YP9XP1//o4Zyxzz1vMpkWvDGr4PLFhX97d9PGnXwX/txXXqisrGh5B7hcLvyXLVs2rFn99d49hzUazYcfvXP0aPamjbu+2ZSRk3Nm7977N0y2sPE/uQX0wNmBrMy5c97I2J0Nx5L9Y9a+/bupLcDnlu82JCb0fG3+ouSRY3LOn5XXy6lfqVQqODNRXWKQNbCOtvi4xCtXHmq7lJ87fFhKVXVlTU019dXT0ysoKASm1Wr1lMkvDho4zN8voLlNwfolJcVvLU6Hg4fyb94rC52dnfdkbm95BxgMhk6ngysgwD+Qz+fDbysqyl5fsAT+Nfx1iYq5detGyxv/k1sADdu2f/PC9Fm9e/d3FbgOGTwidcyEb779ymw2U3vSI7F32rjJHSM7Dxo4HEQePnyImn/8xGE2m92xYxdkDayjLaF7z/p6+d27d9CDUxMXlwj7d/HSBfhaUJDXPT6pcc1OnaJa3hRkmzweLzY2/uH+MZnR0XF5eTkt/4rKpkJCOlBf+XyBh8RTJHp4txqkKrVa1fLG/+QWykpLDAZD06MIC4uUyaSVVQ/zAxBGTYCzYUOfPXykUduRwYNGgDlkDayzFbge/f0D8wvy4Djv3bsbEx0HuQEIGzxoeG5ezl9fno8eXM7w+YeHzx5FqVRotVooJJrOhPil5V9RJ536FxSgpOlSKjW0sPE/uYXauhr45DnxGhe5OLvAp0at5nA49w+Q9/ui0aPSoIyETFggcIVsdu3qr5GVsFokmdA96erVAh7PGS43cBMd3Q3KCQg0IEJJ6tkX/XZe4LPpqXkUOImQR6UvW/U/e8myzn4+/cYhFcKnVvf7fXBqjZraslwuQ78dJkVYWERkRKeDP+wNCgqFy7pLl2hkJaymrVu3hI3//gJyBsh24Gt0126Ft26cOX0iIryj0FXY8m+bigwNDYfS29vbF4IUag4EexKxB7IGT79xyBJZLFZ+fh74oOZALAbOIJuhtP2B5ORUiB47hIZDhIKsh9Wq21CelZeXnjlzMjbmfsnh5uYeGBi8Z++O+Pgej/2tn18AhDCnTh27V1oCsQD8rVyZXlVVCWUGxOWz50z98aeDyBo8/cbhEhwyZCSEi6dPn4AqwQ+H9mdlZUIM0tz6UJ5VVVX8eu6XoUOSkfWwWmoTCUVhHSKg3gP+qDlQvMFRNX5tgd69+v90+Id33vvbyy/NmzxpxoqPP83cu/OD9MUQnUIImjwydVSK1R4tfPqNz5u7EDWgZcuXGI1GyPogqhyf1uyz4QKBAGpHEIlA4Iqsh+VHN04fqG1AzOh+7ojwdEAEBI0Mby1e1vNBAf9EXDouZTLNvZ6VPLqI9ADQRUVFeWlZye6MraGhYa1w1jLYaFvy9oKC/DyLi0aPToPcFbUxoMa2YePnUVExS99dgawNNpkktLCYzJafGuKwObwmtSWHwREySRcXF0T4DVK2YQnRhiVEG5YQbVhCtGEJ0YYlRBuWEG1YYrnjhkEGJGkbNNejbNmPUMxRSA2IYFeUUoNIwrG4yLI2D3+nymINItiVyrsaz0DLba2WtXkGcF1cWZd/kSGCnSg4JXUWsDz8LI/F1EzZxmAMm+pTcLLu4s91iGBzco/UXv5FOnKGT3MrtDSepFJmzP6usrJY6+bJ5ThhFqWYHxwXk4HZEFQGnVlWrfcJ4Q2b6s0XNRvnP37QXa3KVF9nhM0hrPj+++/hc9SoUQgruDymqzubx2e1vNrj622wicdupQ3CcJFCVu8f7owcEVLdxhKiDUuINiwh2rCEaMMSog1LiDYsIdqwhGjDEqINS4g2LCHasIRowxKiDUuINiwh2rCEaMMSog1LiDYsIdqwhGjDEqINS4g2LCHasIRowxKiDUuINiwh2rCEaMMSog1LiDYsIdqwhGjDEqINS4g2LCHasIRowxKiDUuINiwh2rDk8aMA4UVKSkpZWdkfZvr5+R04cAA5EI423mdycjLzEUaOHIkcC0fTlpaWFhQU1HROcHDwpEmTkGPhaNq8vLyGDBnSdM6gQYPEYmu+8q4t4ICDIo8bNy4kJISahpQ3fvx45HA4oDZvb+8BAwZQ00OHDoX0hxwOxxyCfMKECZDgIKlBUYccETtXAFT1plsXlfIag1pp0ipNOp3VdqaqsgoxkBWTmpMTgydguQhYIg9OWKyAL7TnGJt203bhiPRaDgjTu3nz2S4cFofF5rBY7Lab+k1Gs0lvMhpNRrVBVqly8+R2TnTtNsAN2QM7aCu8qDqeUc3hc0Q+QqEXru9ArK9Sy8vqjTpDv+c8w2P5yLbYVJtB13BgY4W02ugd7s4XO8JwuMpabdWtOrEXO2WmD5tru+G0badNKTNm/KvUScj3iXS013lXXK/TKzVj5/kJ3GzUxmsjbTVl+j3/uucR6i4OFCJHpO5ufc0d6bj5ARJfLqIfW4QAWpVp37oyrwiJozoDxEFCOMC9X5ZplCZEP7RrMxkb9nxeJvAUuPkKkEMDByjwEIA5k4n2DIx2beeypSYz0yvMPoGyjfEKdzOaWOd/ov0NM/RqU8lN+SflflFeDNxeWtI64DD9unhePFZPd1ZJr7aT+2vcA1zbciXa6rA4TDd/4anvaxGd0HhC9Vpz8RW1e1AbzR5l8sqF7yYVXD2OrA1EXtBiB4ePaINGbUX5KpEPn8VqF9ljU+4nOB/+nSsqRBs0art5UckTOeabgR4LHHhhLo3aaKzVVxXrQhI9ED3UK2r3/7D6zt1LBoOuU2TvoQNmekgCYP6J0zuOntjy1xn/2rxtUXVNsa9PxMC+0+Jjh1O/yr2Ufejweq1W2aVTv/69JiLa4Euc756nMZ6kLbU1IGh+gewC0YDJZPry33PA2fgxby98dRvPif/pVy9KZRWwiM3marT1mVkrJ459b2X62c6RfXZkLlMo75/B8srCrbvf6xE/avGC3XHRwzKzViHaYHOY92tvtNXf6NKmlBvZXLo2frs4D1LSpHHvd4xIchWIxyS/4cR1PnlmJ3oQgkP6GzlkTnBgV/jao/sok8lYVn4Tpn85myF28xv8zAxnZ9fI8B6J8SmITsCcSkFXNYCuM6uQGmlKasCduxe5HF5YaDz1lclkhgZ3Kyw6D9NUE2ugfxdqEc/pftOMRquAz+rau97eHRo3EujfGdEJ9CBC6zmiB7rKtoYHmSRNaLRKvUEL4XvTmUJXj4f/+EGao2Y2jWLV6noB//fOBy6H5nCpAZmNdJ0CurS5uLKMOrqyCFeBBMqzGZP/0XQmk/WYuwQgbwTZjV91OhojPcCoN7nQduMCjdr0tGnz9QnX6lTubj4SsT81p6bunlDwmKgV1r9+84zZbIZMFb5evXEK0YlebXRxpev00lX8cHlMs9Gs19CSuXcMT4oMT9q590No6VCqpBD0r/nyhfMXf2j5VzFRgxXK2qzsz6D8u3nr3OlzmYg2DFpjAwNxnOhqaqCx3uYVxFPWasQBrogGXpq25tTZXVt2vF1cku/lEZLUfUyvxOda/kmXjn1Shr96+tc9x079R+zuBzUEqEXQVALXV6l9gnmINmjs3b50Ql5wVuUX5Y3aH6X5lbF9+V17ixA90Ni4FR4rkJZrDDpb9Pa2KYxak7xaE9GNlmyGgsZMEuKo8BhBXbHMO1JicQVo7Fi6YpjFRUajns3iIktFg593xNyX1iHr8e6HQ5przzCbTUymhWgwNCh25rR/omaoKZZFxAmcXGhMEvTeAqSSG7/9sDi8dyDHyXIoXCctszgfmg15PMs3MbBYHJHQE1mP5vYB0Bt0XI7To/PhkhIKLQeuEIwU/nJv+jshfBGNty3TfufWqf21RVc0ATE+7aGDG07m3dzyyG4uvZ6VIDqhvd85aaQ7z6mhpkiK2gHVt6QCIaPHcNofp6NdG7Sops71N6q18nIlcmhk5UqTRjt6lj+LTXu+YqPbW7Vq8751ZWy+s6St3qPwlNQWy4xqTepsP1ojkUZsdzO5ydiQ/V2lrLbBu5Mnk+k45ZzZ3FB+pUrsyRw+zZtpqzswbP3EzfmfpAWnFZJQsUDiCPcrKGrUtUV1Mf1E8YNsmovY4UEpWbUh92dZdZmRJ3RxETuzufZ8vq91QIVaJdfoZGrvQE7cAJFQwkG2xZ5Pkxblq65fUNWU6RlMBnQqMtgsqm2+bQJdBw0G6Co3QZgv8eV2TuCHRNn6sbZG2sQoQNALDElQXmNQ1RuR/XfHEgzEF7HdPDhunhyYQPbG0QZvaieQodKwhGjDEqINS4g2LCHasIRow5L/BwAA//9cc1LcAAAABklEQVQDAHw36ucsUOviAAAAAElFTkSuQmCC",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.store.base import BaseStore\n",
    "\n",
    "# Initialize the model\n",
    "model = ChatGroq(model_name = \"meta-llama/llama-4-scout-17b-16e-instruct\", groq_api_key=groq_api_key)\n",
    "\n",
    "# Schema \n",
    "class UserProfile(BaseModel):\n",
    "    \"\"\" Profile of a user \"\"\"\n",
    "    user_name: str = Field(description=\"The user's preferred name\")\n",
    "    user_location: str = Field(description=\"The user's location\")\n",
    "    interests: list = Field(description=\"A list of the user's interests\")\n",
    "\n",
    "# Create the extractor\n",
    "trustcall_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[UserProfile],\n",
    "    tool_choice=\"UserProfile\", # Enforces use of the UserProfile tool\n",
    ")\n",
    "\n",
    "# Chatbot instruction\n",
    "MODEL_SYSTEM_MESSAGE = \"\"\"You are a helpful assistant with memory that provides information about the user. \n",
    "If you have memory for this user, use it to personalize your responses.\n",
    "Here is the memory (it may be empty): {memory}\"\"\"\n",
    "\n",
    "# Extraction instruction\n",
    "TRUSTCALL_INSTRUCTION = \"\"\"Create or update the memory (JSON doc) to incorporate information from the following conversation:\"\"\"\n",
    "\n",
    "def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Load memory from the store and use it to personalize the chatbot's response.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Retrieve memory from the store\n",
    "    namespace = (\"memory\", user_id)\n",
    "    existing_memory = store.get(namespace, \"user_memory\")\n",
    "\n",
    "    # Format the memories for the system prompt\n",
    "    if existing_memory and existing_memory.value:\n",
    "        memory_dict = existing_memory.value\n",
    "        formatted_memory = (\n",
    "            f\"Name: {memory_dict.get('user_name', 'Unknown')}\\n\"\n",
    "            f\"Location: {memory_dict.get('user_location', 'Unknown')}\\n\"\n",
    "            f\"Interests: {', '.join(memory_dict.get('interests', []))}\"      \n",
    "        )\n",
    "    else:\n",
    "        formatted_memory = None\n",
    "\n",
    "    # Format the memory in the system prompt\n",
    "    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=formatted_memory)\n",
    "\n",
    "    # Respond using memory as well as the chat history\n",
    "    response = model.invoke([SystemMessage(content=system_msg)]+state[\"messages\"])\n",
    "\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Reflect on the chat history and save a memory to the store.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Retrieve existing memory from the store\n",
    "    namespace = (\"memory\", user_id)\n",
    "    existing_memory = store.get(namespace, \"user_memory\")\n",
    "        \n",
    "    # Get the profile as the value from the list, and convert it to a JSON doc\n",
    "    existing_profile = {\"UserProfile\": existing_memory.value} if existing_memory else None\n",
    "    \n",
    "    # Invoke the extractor\n",
    "    result = trustcall_extractor.invoke({\"messages\": [SystemMessage(content=TRUSTCALL_INSTRUCTION)]+state[\"messages\"], \"existing\": existing_profile})\n",
    "    \n",
    "    # Get the updated profile as a JSON object\n",
    "    updated_profile = result[\"responses\"][0].model_dump()\n",
    "\n",
    "    # Save the updated profile\n",
    "    key = \"user_memory\"\n",
    "    store.put(namespace, key, updated_profile)\n",
    "\n",
    "# Define the graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"call_model\", call_model)\n",
    "builder.add_node(\"write_memory\", write_memory)\n",
    "builder.add_edge(START, \"call_model\")\n",
    "builder.add_edge(\"call_model\", \"write_memory\")\n",
    "builder.add_edge(\"write_memory\", END)\n",
    "\n",
    "# Store for long-term (across-thread) memory\n",
    "across_thread_memory = InMemoryStore()\n",
    "\n",
    "# Checkpointer for short-term (within-thread) memory\n",
    "within_thread_memory = MemorySaver()\n",
    "\n",
    "# Compile the graph with the checkpointer fir and store\n",
    "graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "18d6ffa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Assalamualikum, i'm Al Amin\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Wa alaikumussalam, Al Amin! It's nice to meet you. How are you doing today?\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory \n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n",
    "\n",
    "# User input \n",
    "input_messages = [HumanMessage(content=\"Assalamualikum, i'm Al Amin\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1a08b469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I like to bike around Bashundhara r/a Dhaka\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Biking around Bashundhara Residential Area (R/A) in Dhaka can be a great way to stay active and enjoy the outdoors. The area has some nice roads and scenery, I'm sure. Do you have a favorite route or spot that you like to visit while biking?\n"
     ]
    }
   ],
   "source": [
    "# User input \n",
    "input_messages = [HumanMessage(content=\"I like to bike around Bashundhara r/a Dhaka\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3468941d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': ['memory', '1'],\n",
       " 'key': 'user_memory',\n",
       " 'value': {'user_name': 'Al Amin',\n",
       "  'user_location': 'Bashundhara r/a Dhaka',\n",
       "  'interests': []},\n",
       " 'created_at': '2025-05-12T12:00:34.975462+00:00',\n",
       " 'updated_at': '2025-05-12T12:00:34.975462+00:00'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Namespace for the memory to save\n",
    "user_id = \"1\"\n",
    "namespace = (\"memory\", user_id)\n",
    "existing_memory = across_thread_memory.get(namespace, \"user_memory\")\n",
    "existing_memory.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5ae31e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_name': 'Al Amin',\n",
       " 'user_location': 'Bashundhara r/a Dhaka',\n",
       " 'interests': []}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_memory.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "454f3a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I also enjoy going to bakeries\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That sounds delicious! Bakeries can be a great place to indulge in sweet treats and freshly baked goods. Are you a fan of traditional Bangladeshi baked goods or do you prefer international flavors like croissants or pastries? Are there any specific bakeries in Bashundhara R/A or nearby that you particularly enjoy visiting?\n"
     ]
    }
   ],
   "source": [
    "# User input \n",
    "input_messages = [HumanMessage(content=\"I also enjoy going to bakeries\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "54f4a514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': ['memory', '1'],\n",
       " 'key': 'user_memory',\n",
       " 'value': {'user_name': 'Al Amin',\n",
       "  'user_location': 'Bashundhara r/a Dhaka',\n",
       "  'interests': ['biking', 'bakeries']},\n",
       " 'created_at': '2025-05-12T12:02:34.842104+00:00',\n",
       " 'updated_at': '2025-05-12T12:02:34.842104+00:00'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Namespace for the memory to save\n",
    "user_id = \"1\"\n",
    "namespace = (\"memory\", user_id)\n",
    "existing_memory = across_thread_memory.get(namespace, \"user_memory\")\n",
    "existing_memory.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "06d031cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What bakeries do you recommend for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "As Al Amin, I'm excited to share some of my favorite bakeries in Dhaka with you! Being a resident of Bashundhara R/A, I've had the chance to try out a few amazing bakeries in the area.\n",
      "\n",
      "One of my top recommendations is **Banani Bakeshop**. Their freshly baked croissants and danishes are simply divine! They also have a wide variety of cakes, pastries, and sandwiches.\n",
      "\n",
      "Another favorite of mine is **The Baker's Oven** in Gulshan. Their sourdough bread and artisanal cakes are made with love, and you can taste the difference. Plus, their cozy atmosphere makes it a great spot to grab a coffee and pastry.\n",
      "\n",
      "If you're looking for something a bit more budget-friendly, I'd suggest checking out **Nadia's Bake Shop** in Uttara. They offer a range of delicious baked goods, from traditional Bangladeshi desserts to Western-style treats.\n",
      "\n",
      "Lastly, if you're willing to venture a bit further, **C&C Cake & Bakery** in Dhanmondi is definitely worth a visit. Their cakes are moist and flavorful, and they have a lovely selection of desserts and snacks.\n",
      "\n",
      "Hope you enjoy exploring these bakeries! As a biking enthusiast, I love discovering new spots to grab a coffee and pastry on my rides around the city.\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory \n",
    "config = {\"configurable\": {\"thread_id\": \"2\", \"user_id\": \"1\"}}\n",
    "\n",
    "# User input \n",
    "input_messages = [HumanMessage(content=\"What bakeries do you recommend for me?\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ee0bff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_aca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
