{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb6cb737",
   "metadata": {},
   "source": [
    "## Updating collection schema\n",
    "\n",
    "We discussed the challenges with updating a profile schema in the last lesson.\n",
    "\n",
    "The same applies for collections!\n",
    "\n",
    "We want the ability to update the collection with new memories as well as update existing memories in the collection.\n",
    "\n",
    "Now we'll show that [Trustcall](https://github.com/hinthornw/trustcall) can be also used to update a collection.\n",
    "\n",
    "This enables both addition of new memories as well as [updating existing memories in the collection](https://github.com/hinthornw/trustcall?tab=readme-ov-file#simultanous-updates--insertions\n",
    ").\n",
    "\n",
    "Let's define a new extractor with Trustcall.\n",
    "\n",
    "As before, we provide the schema for each memory, `Memory`.  \n",
    "\n",
    "But, we can supply `enable_inserts=True` to allow the extractor to insert new memories to the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0294c40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "model = ChatGroq(model=\"meta-llama/llama-4-scout-17b-16e-instruct\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "304d61e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "class Memory(BaseModel):\n",
    "    \"\"\"This is the memory field where store the collection of user data like his interested, his name, and so one. in one word all about the user info.\"\"\"\n",
    "    content: str = Field(description=\"The main content of the memory. User expressed interested in learning Programming.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "488ab9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trustcall import create_extractor\n",
    "\n",
    "trustcall_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[Memory],\n",
    "    tool_choice=\"Memory\",\n",
    "    enable_inserts=True,\n",
    "    \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "093948bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "# Instruction\n",
    "instruction = \"\"\"Extract memories from the following conversation:\"\"\"\n",
    "\n",
    "# Conversation\n",
    "conversation = [HumanMessage(content=\"Hi, I'm Al Amin\"),\n",
    "                AIMessage(content=\"Nice to meet you, Al Amin.\"),\n",
    "                HumanMessage(content=\"This morning I had a nice bike ride in Dhaka.\")]\n",
    "\n",
    "\n",
    "result = trustcall_extractor.invoke(\n",
    "    {\n",
    "        \"messages\": [SystemMessage(content=instruction)]+conversation\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2eb2fe67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_g0zg)\n",
      " Call ID: call_g0zg\n",
      "  Args:\n",
      "    content: Al Amin had a bike ride in Dhaka.\n"
     ]
    }
   ],
   "source": [
    "for m in result['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "440a4133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'Al Amin had a bike ride in Dhaka.'}\n"
     ]
    }
   ],
   "source": [
    "for m in result['responses']:\n",
    "    print(m.model_dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a977973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'call_g0zg'}\n"
     ]
    }
   ],
   "source": [
    "for m in result['response_metadata']:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d7b30c",
   "metadata": {},
   "source": [
    "### **Update the memory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18a73a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the conversation\n",
    "updated_conversation = [AIMessage(content=\"That's great, did you do after?\"),\n",
    "                        HumanMessage(content=\"I went to Tartine and ate a croissant.\"),\n",
    "                        AIMessage(content=\"What else is on your mind?\"),\n",
    "                        HumanMessage(content=\"I was thinking about my Japan, and going back this winter!\"),]\n",
    "\n",
    "# Update the instruction\n",
    "system_msg = \"\"\"Update existing memories and create new ones based on the following conversation:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e729bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0', 'Memory', {'content': 'Al Amin had a bike ride in Dhaka.'})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Extracting the existing memory.\n",
    "tool_name = \"Memory\"\n",
    "existing_memories = [(str(i), tool_name, memory.model_dump()) for i, memory in enumerate(result['responses'])] if result['responses'] else None\n",
    "existing_memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e017f975",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Update the memory\n",
    "result = trustcall_extractor.invoke(\n",
    "    {\n",
    "        \"messages\": updated_conversation,\n",
    "        \"existing\": existing_memories\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efd79c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_q4qp)\n",
      " Call ID: call_q4qp\n",
      "  Args:\n",
      "    content: Al Amin had a bike ride in Dhaka. I went to Tartine and ate a croissant. I was thinking about my Japan, and going back this winter!\n"
     ]
    }
   ],
   "source": [
    "# Messages from the model indicate two tool calls were made\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d601ee1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Al Amin had a bike ride in Dhaka. I went to Tartine and ate a croissant. I was thinking about my Japan, and going back this winter!'\n"
     ]
    }
   ],
   "source": [
    "for m in result[\"responses\"]:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ad6ab68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'call_q4qp'}\n"
     ]
    }
   ],
   "source": [
    "# Metadata contains the tool call\n",
    "for m in result[\"response_metadata\"]:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0365b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_aca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
