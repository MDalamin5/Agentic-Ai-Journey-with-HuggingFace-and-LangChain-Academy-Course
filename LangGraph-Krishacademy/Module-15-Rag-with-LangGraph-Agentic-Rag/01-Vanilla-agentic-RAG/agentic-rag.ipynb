{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d359e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"HF_TOKEN\"]=os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "llm = ChatGroq(model=\"qwen-qwq-32b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84654be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma, FAISS\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa283102",
   "metadata": {},
   "source": [
    "## **Retriever for the LangGraph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d800e3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://langchain-ai.github.io/langgraph/\",\n",
    "    \"https://modelcontextprotocol.io/introduction\",\n",
    "    \"https://langchain-ai.github.io/langgraph/agents/multi-agent/\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a73edee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e1f0d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/', 'title': 'LangGraph', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Prebuilt agents\\n    \\n  \\n\\n\\n\\n\\n\\n            Prebuilt agents\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n    Running agents\\n    \\n  \\n\\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n    Models\\n    \\n  \\n\\n\\n\\n\\n\\n    Tools\\n    \\n  \\n\\n\\n\\n\\n\\n    MCP Integration\\n    \\n  \\n\\n\\n\\n\\n\\n    Context\\n    \\n  \\n\\n\\n\\n\\n\\n    Memory\\n    \\n  \\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n    Multi-agent\\n    \\n  \\n\\n\\n\\n\\n\\n    Evals\\n    \\n  \\n\\n\\n\\n\\n\\n    Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n    UI\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph framework\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph framework\\n          \\n\\n\\n\\n\\n    Agent architectures\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Graphs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Persistence\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Memory\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Breakpoints\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tools\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Subgraphs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Multi-agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Functional API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph Platform\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph Platform'), Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/', 'title': 'LangGraph', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='Multi-agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Functional API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph Platform\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph Platform\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Components\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Data management\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Authentication & access control\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Assistants\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Threads\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Runs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n    Breakpoints\\n    \\n  \\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n    MCP\\n    \\n  \\n\\n\\n\\n\\n\\n    Double-texting\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Webhooks\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Cron jobs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Server customization\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Reference\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Examples\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Resources\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      Get started\\n    \\n\\n\\n\\n\\n\\n      Core benefits\\n    \\n\\n\\n\\n\\n\\n      LangGraph’s ecosystem\\n    \\n\\n\\n\\n\\n\\n      Additional resources\\n    \\n\\n\\n\\n\\n\\n      Acknowledgements')]\n"
     ]
    }
   ],
   "source": [
    "doc_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "\n",
    "doc_splits = text_splitter.split_documents(documents=doc_list)\n",
    "print(doc_splits[1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0ec00b",
   "metadata": {},
   "source": [
    "## ***Use HuggingFace Embedding Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "827e41fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\envs\\lang_aca\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceBgeEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a357ee9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=embeddings,\n",
    ")\n",
    "\n",
    "langGraph_retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19eae0be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/', 'title': 'LangGraph', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='LangGraph\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Skip to content\\n        \\n\\n\\n\\n\\n\\n\\n\\nWe are growing and hiring for multiple roles for LangChain, LangGraph and LangSmith.  Join our team!\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            LangGraph\\n          \\n\\n\\n\\n            \\n              LangGraph\\n            \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Initializing search\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Guides\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Reference\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Examples\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Resources\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph\\n  \\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Guides\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n            Guides\\n          \\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n            Get started\\n          \\n\\n\\n\\n\\n    Quickstart\\n    \\n  \\n\\n\\n\\n\\n\\n    LangGraph basics\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Prebuilt agents\\n    \\n  \\n\\n\\n\\n\\n\\n            Prebuilt agents\\n          \\n\\n\\n\\n\\n    Overview'),\n",
       " Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/', 'title': 'LangGraph', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='Note\\nLooking for the JS version of LangGraph? See the JS repo and the JS docs.\\n\\nAdditional resources¶\\n\\nGuides: Quick, actionable code snippets for topics such as streaming, adding memory & persistence, and design patterns (e.g. branching, subgraphs, etc.).\\nReference: Detailed reference on core classes, methods, how to use the graph and checkpointing APIs, and higher-level prebuilt components.\\nExamples: Guided examples on getting started with LangGraph.\\nLangChain Academy: Learn the basics of LangGraph in our free, structured course.\\nTemplates: Pre-built reference apps for common agentic workflows (e.g. ReAct agent, memory, retrieval etc.) that can be cloned and adapted.\\nCase studies: Hear how industry leaders use LangGraph to ship AI applications at scale.\\n\\nAcknowledgements¶\\nLangGraph is inspired by Pregel and Apache Beam. The public interface draws inspiration from NetworkX. LangGraph is built by LangChain Inc, the creators of LangChain, but can be used without LangChain.'),\n",
       " Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/agents/multi-agent/', 'title': 'Multi-agent', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='# Run the multi-agent graph\\nfor chunk in multi_agent_graph.stream(\\n    {\\n        \"messages\": [\\n            {\\n                \"role\": \"user\",\\n                \"content\": \"book a flight from BOS to JFK and a stay at McKittrick Hotel\"\\n            }\\n        ]\\n    }\\n):\\n    print(chunk)\\n    print(\"\\\\n\")\\n\\n\\nAccess agent\\'s state\\nThe Command primitive allows specifying a state update and a node transition as a single operation, making it useful for implementing handoffs.\\nName of the agent or node to hand off to.\\nTake the agent\\'s messages and add them to the parent\\'s state as part of the handoff. The next agent will see the parent state.\\nIndicate to LangGraph that we need to navigate to agent node in a parent multi-agent graph.\\n\\n\\nNote\\nThis handoff implementation assumes that:\\n\\neach agent receives overall message history (across all agents) in the multi-agent system as its input\\neach agent outputs its internal messages history to the overall message history of the multi-agent system'),\n",
       " Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/', 'title': 'LangGraph', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='# Run the agent\\nagent.invoke(\\n    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\\n)\\n\\nFor more information, see the Quickstart. Or, to learn how to build an agent workflow with a customizable architecture, long-term memory, and other complex task handling, see the LangGraph basics tutorials.\\nCore benefits¶\\nLangGraph provides low-level supporting infrastructure for any long-running, stateful workflow or agent. LangGraph does not abstract prompts or architecture, and provides the following central benefits:')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Why Lnaggraph is important?\"\n",
    "\n",
    "response = langGraph_retriever.invoke(query)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9379cd6d",
   "metadata": {},
   "source": [
    "## Make this retriever into a retriever tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65f38e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "langGraph_retriever_tool = create_retriever_tool(\n",
    "    langGraph_retriever,\n",
    "    \"retriever_vector_db_blog\",\n",
    "    \"Search and run information abut Model Context Protocol(MCP) and multi-agent system.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4239058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tool(name='retriever_vector_db_blog', description='Search and run information abut Model Context Protocol(MCP) and multi-agent system.', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x0000020B92E9C180>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceBgeEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000020BB2A78F50>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x0000020B92E9F560>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceBgeEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000020BB2A78F50>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langGraph_retriever_tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3e92a3",
   "metadata": {},
   "source": [
    "# **LangChain blogs - Separate Vector DB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa7bbde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://python.langchain.com/docs/tutorials/\",\n",
    "    \"https://python.langchain.com/docs/introduction/\",\n",
    "    \"https://python.langchain.com/docs/versions/v0_3/\"   \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f860d364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df7e905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list = [item for sublist in docs for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92cf5b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "\n",
    "doc_splits = text_splitter.split_documents(documents=doc_list)\n",
    "\n",
    "vectorstore_langChain = FAISS.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdb066a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://python.langchain.com/docs/introduction/', 'title': 'Introduction | 🦜️🔗 LangChain', 'description': 'LangChain is a framework for developing applications powered by large language models (LLMs).', 'language': 'en'}, page_content='Introduction | 🦜️🔗 LangChain'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/versions/v0_3/', 'title': 'LangChain v0.3 | 🦜️🔗 LangChain', 'description': 'Last updated: 09.16.24', 'language': 'en'}, page_content='LangChain v0.3 | 🦜️🔗 LangChain'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/', 'title': 'Tutorials | 🦜️🔗 LangChain', 'description': 'New to LangChain or LLM app development in general? Read this material to quickly get up and running building your first applications.', 'language': 'en'}, page_content='Tutorials | 🦜️🔗 LangChain'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/introduction/', 'title': 'Introduction | 🦜️🔗 LangChain', 'description': 'LangChain is a framework for developing applications powered by large language models (LLMs).', 'language': 'en'}, page_content='LangChain is a framework for developing applications powered by large language models (LLMs).\\nLangChain simplifies every stage of the LLM application lifecycle:')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langChain_retriever = vectorstore_langChain.as_retriever()\n",
    "\n",
    "langChain_retriever.invoke(\"Why langChain?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e57217c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "langChain_retriever_tool = create_retriever_tool(\n",
    "    retriever=langChain_retriever,\n",
    "    name=\"Retriever_vector_langchain_blog\",\n",
    "    description=\"Search and run information about langchain tutorial and different version.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a50c90cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tool(name='Retriever_vector_langchain_blog', description='Search and run information about langchain tutorial and different version.', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x0000020B92E9C180>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceBgeEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000020BB2AC8ED0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x0000020B92E9F560>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceBgeEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000020BB2AC8ED0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langChain_retriever_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7e786b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [langChain_retriever_tool, langGraph_retriever_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7c6cf9",
   "metadata": {},
   "source": [
    "# ***Now Time To Build The Agentic RAG***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c722d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\n<think>\\nOkay, the user said \"Hello sir!!\". I need to respond appropriately. Let me start with a friendly greeting. Maybe \"Hello! How can I assist you today?\" That\\'s standard but polite.\\n\\nWait, they used \"sir\", maybe they expect a more formal response? Should I use \"Good day\" instead? Hmm, but \"Hello\" is also common. Let me check if there\\'s any context I\\'m missing. Since it\\'s the first message, probably not. Keep it simple and open-ended. Make sure to offer help. Yeah, that should be good. Let me go with that.\\n</think>\\n\\nHello! How can I assist you today? 😊', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 138, 'prompt_tokens': 13, 'total_tokens': 151, 'completion_time': 0.335488406, 'prompt_time': 0.002878349, 'queue_time': 0.162174466, 'total_time': 0.338366755}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_512a3da6bb', 'finish_reason': 'stop', 'logprobs': None}, id='run--f4197476-16bb-4ee8-83b9-72f5fb521f8f-0', usage_metadata={'input_tokens': 13, 'output_tokens': 138, 'total_tokens': 151})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "llm.invoke([HumanMessage(content=\"Hello sir!!\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6aa52003",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Sequence\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de1aca9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d4a8d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent(state: AgentState):\n",
    "    \"\"\"\n",
    "    Invokes the agent model to generate a response based on the current state. Given the question,\n",
    "    it will decide to retrieve using the retriever tool, or simple end e.g. like response by llm only.\n",
    "    \n",
    "    Args:\n",
    "        state(messages): The current state.\n",
    "    \n",
    "    Returns:\n",
    "        dict: The update state with the agent response appended to messages.\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\"--Calling Agent--\")\n",
    "    messages = state['messages']\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    \n",
    "    print(response)\n",
    "    # we return the list, because this will get added to the existing list.\n",
    "    return {\n",
    "        \"messages\": [response]\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3aa74ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from typing import List, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "def grade_documents(state: AgentState) -> Literal[\"generate\", \"rewrite\"]:\n",
    "    \"\"\"\n",
    "    Determine the retrieved documents are relevant to the question or not.\n",
    "    \n",
    "    Args:\n",
    "        state(messages): The current state.\n",
    "    \n",
    "    Return:\n",
    "        str: A decision for weather the document are relevant or not.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"---Checking The document---\")\n",
    "    \n",
    "    ## Data schema\n",
    "    class Grade(BaseModel):\n",
    "        \"\"\"Binary score for relevance score check.\"\"\"\n",
    "        binary_score: Literal['yes', 'no'] = Field(description=\"relevance score 'yes' or 'no' \")\n",
    "        \n",
    "    llm_with_str_op = llm.with_structured_output(Grade)\n",
    "    \n",
    "    ## Define the prompt\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "        You are a grader assessing relevance of a retrieved document toa user question. \\n\n",
    "        Here is the retrieve document: \\n\\n {context} \\n\\n\n",
    "        And this is the user question: {question} \\n\n",
    "        if the document contains keyword(s) or semantic meaning related to the user question grade it as relevant.\\n\n",
    "        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant ot the question.\n",
    "        \"\"\",\n",
    "        input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "    \n",
    "    chain = prompt | llm_with_str_op\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    last_messages = messages[-1]\n",
    "    docs = last_messages.content\n",
    "    question = messages[0].content\n",
    "    print(question)\n",
    "    \n",
    "    scored_result = chain.invoke(\n",
    "        {\n",
    "            \"context\": docs,\n",
    "            \"question\": question\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    score = scored_result.binary_score\n",
    "    \n",
    "    if score == 'yes':\n",
    "        print(\"---Decision: docs is relevance\")\n",
    "        return \"generate\"\n",
    "    else:\n",
    "        print(\"---This is not relevance---\")\n",
    "        return \"rewrite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1601f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state: AgentState):\n",
    "    \"\"\"\n",
    "    Generate answer based on the context and user query.\n",
    "    \n",
    "    Args:\n",
    "        state(messages): The current state\n",
    "        \n",
    "    Returns:\n",
    "        dict: The updated messages\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"---Generative---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "    docs = messages[-1].content\n",
    "    \n",
    "    prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "    \n",
    "    ## format the docs\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    \n",
    "    parser = StrOutputParser()\n",
    "    ## rag chain\n",
    "    rag_chain = prompt | llm | parser\n",
    "    \n",
    "    ## run\n",
    "    response = rag_chain.invoke(\n",
    "        {\n",
    "            \"context\": docs,\n",
    "            \"question\": question\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [response]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de82cfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite(state: AgentState):\n",
    "    \"\"\"\n",
    "    Transform the query to produce a bette question.\n",
    "    \n",
    "    Args:\n",
    "        state(messages): the current state\n",
    "        \n",
    "    Returns:\n",
    "        dict: THe updated state with re-phrased question.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"--Transform query\")\n",
    "    messages = state['messages']\n",
    "    question = messages[0].content\n",
    "    \n",
    "    msg = [\n",
    "        HumanMessage(content=f\"\"\"\\n\n",
    "                     Look at the input and try to reason about the underlying semantic intent meaning. \\n\n",
    "                     Here is the initial question:\n",
    "                     \\n\\n\n",
    "                     {question}\\n\\n\n",
    "                     Formulate an improve question: \n",
    "                     \"\"\",)\n",
    "    ]\n",
    "    response = llm.invoke(msg)\n",
    "    return {\n",
    "        \"messages\": [response]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd72f32",
   "metadata": {},
   "source": [
    "## **Build the graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb00f368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.graph import START, StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from IPython.display import display, Image\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"agent\", agent)\n",
    "workflow.add_node(\"retrieve\", ToolNode(tools))\n",
    "workflow.add_node(\"rewrite\", rewrite)\n",
    "workflow.add_node(\"generate\", generate)\n",
    "\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    # Assess agent decision\n",
    "    #\n",
    "    tools_condition,\n",
    "    {\n",
    "        # translate the condition output to nodes in out graph\n",
    "        \"tools\": \"retrieve\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"retrieve\",\n",
    "    #\n",
    "    #\n",
    "    grade_documents,\n",
    ")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "workflow.add_edge(\"rewrite\", \"agent\")\n",
    "\n",
    "graph = workflow.compile()\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27faeb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Calling Agent--\n",
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_2jcs', 'function': {'arguments': '{\"query\": \"Why LangGraph is important for Agentic workflows instead of LangChain, focusing on multi-agent systems and dynamic workflows\"}', 'name': 'retriever_vector_db_blog'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 1249, 'prompt_tokens': 269, 'total_tokens': 1518, 'completion_time': 3.045856789, 'prompt_time': 0.016664861, 'queue_time': 0.25032559000000004, 'total_time': 3.06252165}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_1e88ca32eb', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--f1c94e12-32bd-4696-89ee-48323f910459-0' tool_calls=[{'name': 'retriever_vector_db_blog', 'args': {'query': 'Why LangGraph is important for Agentic workflows instead of LangChain, focusing on multi-agent systems and dynamic workflows'}, 'id': 'call_2jcs', 'type': 'tool_call'}] usage_metadata={'input_tokens': 269, 'output_tokens': 1249, 'total_tokens': 1518}\n",
      "---Checking The document---\n",
      "Why langgraph is important to building of Agentic workflow instead of using langcahin\n",
      "---Decision: docs is relevance\n",
      "---Generative---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Why langgraph is important to building of Agentic workflow instead of using langcahin', additional_kwargs={}, response_metadata={}, id='247b2530-415c-4f4b-b013-17c4e5b29073'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_2jcs', 'function': {'arguments': '{\"query\": \"Why LangGraph is important for Agentic workflows instead of LangChain, focusing on multi-agent systems and dynamic workflows\"}', 'name': 'retriever_vector_db_blog'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 1249, 'prompt_tokens': 269, 'total_tokens': 1518, 'completion_time': 3.045856789, 'prompt_time': 0.016664861, 'queue_time': 0.25032559000000004, 'total_time': 3.06252165}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_1e88ca32eb', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--f1c94e12-32bd-4696-89ee-48323f910459-0', tool_calls=[{'name': 'retriever_vector_db_blog', 'args': {'query': 'Why LangGraph is important for Agentic workflows instead of LangChain, focusing on multi-agent systems and dynamic workflows'}, 'id': 'call_2jcs', 'type': 'tool_call'}], usage_metadata={'input_tokens': 269, 'output_tokens': 1249, 'total_tokens': 1518}),\n",
       "  ToolMessage(content='Multi-agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Functional API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph Platform\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph Platform\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Components\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Data management\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Authentication & access control\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Assistants\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Threads\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Runs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n    Breakpoints\\n    \\n  \\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n    MCP\\n    \\n  \\n\\n\\n\\n\\n\\n    Double-texting\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Webhooks\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Cron jobs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Server customization\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Reference\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Examples\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Resources\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      Get started\\n    \\n\\n\\n\\n\\n\\n      Core benefits\\n    \\n\\n\\n\\n\\n\\n      LangGraph’s ecosystem\\n    \\n\\n\\n\\n\\n\\n      Additional resources\\n    \\n\\n\\n\\n\\n\\n      Acknowledgements\\n\\nCore benefits\\n    \\n\\n\\n\\n\\n\\n      LangGraph’s ecosystem\\n    \\n\\n\\n\\n\\n\\n      Additional resources\\n    \\n\\n\\n\\n\\n\\n      Acknowledgements\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLangGraph\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTrusted by companies shaping the future of agents – including Klarna, Replit, Elastic, and more – LangGraph is a low-level orchestration framework for building, managing, and deploying long-running, stateful agents.\\nGet started¶\\nInstall LangGraph:\\npip install -U langgraph\\n\\nThen, create an agent using prebuilt components:\\n# pip install -qU \"langchain[anthropic]\" to call the model\\n\\nfrom langgraph.prebuilt import create_react_agent\\n\\ndef get_weather(city: str) -> str:\\n    \"\"\"Get weather for a given city.\"\"\"\\n    return f\"It\\'s always sunny in {city}!\"\\n\\nagent = create_react_agent(\\n    model=\"anthropic:claude-3-7-sonnet-latest\",\\n    tools=[get_weather],\\n    prompt=\"You are a helpful assistant\"\\n)\\n\\n# Run the agent\\nagent.invoke(\\n    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\\n)\\n\\nLangGraph’s ecosystem¶\\nWhile LangGraph can be used standalone, it also integrates seamlessly with any LangChain product, giving developers a full suite of tools for building agents. To improve your LLM application development, pair LangGraph with:\\n\\nLangSmith — Helpful for agent evals and observability. Debug poor-performing LLM app runs, evaluate agent trajectories, gain visibility in production, and improve performance over time.\\nLangGraph Platform — Deploy and scale agents effortlessly with a purpose-built deployment platform for long running, stateful workflows. Discover, reuse, configure, and share agents across teams — and iterate quickly with visual prototyping in LangGraph Studio.\\nLangChain – Provides integrations and composable components to streamline LLM application development.\\n\\n\\nNote\\nLooking for the JS version of LangGraph? See the JS repo and the JS docs.\\n\\nAdditional resources¶\\n\\n# Run the agent\\nagent.invoke(\\n    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\\n)\\n\\nFor more information, see the Quickstart. Or, to learn how to build an agent workflow with a customizable architecture, long-term memory, and other complex task handling, see the LangGraph basics tutorials.\\nCore benefits¶\\nLangGraph provides low-level supporting infrastructure for any long-running, stateful workflow or agent. LangGraph does not abstract prompts or architecture, and provides the following central benefits:', name='retriever_vector_db_blog', id='349ddfce-8383-40bc-a49c-98599eb2ab72', tool_call_id='call_2jcs'),\n",
       "  HumanMessage(content=\"\\n<think>\\nOkay, I need to figure out why LangGraph is important for building Agentic workflows instead of using LangChain. Let me look through the provided context.\\n\\nThe core benefits section says LangGraph offers low-level infrastructure for long-running, stateful workflows. It mentions that it doesn't abstract prompts or architecture, which might mean more control. The ecosystem part talks about integrating with LangChain, but LangGraph specifically handles things like state management, which is crucial for agents that need to maintain context over time. LangChain might be more for composable components, while LangGraph's features like Runs, Threads, and Breakpoints are tailored for managing complex, persistent agent workflows. So, using LangGraph gives better support for those long-lived, stateful processes that agents require, which LangChain alone might not handle as effectively.\\n</think>\\n\\nLangGraph is crucial for Agentic workflows because it provides native support for stateful, long-running processes through features like persistent memory and workflow orchestration. Unlike LangChain, which focuses on composable components, LangGraph's infrastructure inherently manages agent continuity, context retention, and complex task flows essential for autonomous systems. Its integration with tools like LangSmith also enhances debugging and observability for stateful agents.\", additional_kwargs={}, response_metadata={}, id='c3b4b419-2a1b-4f15-aed7-8a31ac56cb41')]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Testing\n",
    "graph.invoke(\n",
    "    {\n",
    "        \"messages\": \"Why langgraph is important to building of Agentic workflow instead of using langcahin\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fd363c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Calling Agent--\n",
      "content='Machine learning (ML) is a subset of artificial intelligence (AI) that focuses on developing algorithms and statistical models enabling computers to improve their performance at specific tasks through experience (data) rather than explicit programming. Instead of being explicitly programmed, ML systems learn patterns from data and make predictions or decisions.\\n\\n### Why Should You Learn Machine Learning?\\n1. **High Demand in Industries**: ML is transforming sectors like healthcare, finance, retail, and autonomous systems, creating numerous job opportunities.\\n2. **Solve Complex Problems**: ML can analyze massive datasets to uncover insights, predict trends (e.g., weather forecasting, stock markets), and automate decision-making.\\n3. **Innovation**: It drives advancements in AI applications like natural language processing (e.g., chatbots), computer vision (e.g., facial recognition), and robotics.\\n4. **Personalized Solutions**: ML enables tailored experiences in recommendation systems (e.g., Netflix, Spotify) and personalized marketing.\\n5. **Automation**: It automates repetitive tasks (e.g., data entry, customer service via chatbots), boosting efficiency and reducing costs.\\n\\nIf you’re interested in a specific application (e.g., LangChain for LLM workflows or MCP for multi-agent systems), let me know, and I can provide deeper insights!' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 616, 'prompt_tokens': 263, 'total_tokens': 879, 'completion_time': 1.499132242, 'prompt_time': 0.020639735, 'queue_time': 0.24274337499999998, 'total_time': 1.519771977}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_512a3da6bb', 'finish_reason': 'stop', 'logprobs': None} id='run--343c2b7f-c579-49ab-ab6f-8a04e263c282-0' usage_metadata={'input_tokens': 263, 'output_tokens': 616, 'total_tokens': 879}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is machine learning and why should i learn it?', additional_kwargs={}, response_metadata={}, id='8f577e78-651d-4e08-9579-5db894918217'),\n",
       "  AIMessage(content='Machine learning (ML) is a subset of artificial intelligence (AI) that focuses on developing algorithms and statistical models enabling computers to improve their performance at specific tasks through experience (data) rather than explicit programming. Instead of being explicitly programmed, ML systems learn patterns from data and make predictions or decisions.\\n\\n### Why Should You Learn Machine Learning?\\n1. **High Demand in Industries**: ML is transforming sectors like healthcare, finance, retail, and autonomous systems, creating numerous job opportunities.\\n2. **Solve Complex Problems**: ML can analyze massive datasets to uncover insights, predict trends (e.g., weather forecasting, stock markets), and automate decision-making.\\n3. **Innovation**: It drives advancements in AI applications like natural language processing (e.g., chatbots), computer vision (e.g., facial recognition), and robotics.\\n4. **Personalized Solutions**: ML enables tailored experiences in recommendation systems (e.g., Netflix, Spotify) and personalized marketing.\\n5. **Automation**: It automates repetitive tasks (e.g., data entry, customer service via chatbots), boosting efficiency and reducing costs.\\n\\nIf you’re interested in a specific application (e.g., LangChain for LLM workflows or MCP for multi-agent systems), let me know, and I can provide deeper insights!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 616, 'prompt_tokens': 263, 'total_tokens': 879, 'completion_time': 1.499132242, 'prompt_time': 0.020639735, 'queue_time': 0.24274337499999998, 'total_time': 1.519771977}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_512a3da6bb', 'finish_reason': 'stop', 'logprobs': None}, id='run--343c2b7f-c579-49ab-ab6f-8a04e263c282-0', usage_metadata={'input_tokens': 263, 'output_tokens': 616, 'total_tokens': 879})]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Testing\n",
    "graph.invoke(\n",
    "    {\n",
    "        \"messages\": \"What is machine learning and why should i learn it?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4cfd92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_aca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
